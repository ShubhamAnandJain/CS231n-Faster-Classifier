{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1653204886178,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "bFB6WDmimTpS",
    "outputId": "672d2a42-ea4c-43f3-e1ca-1367c2868357"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# FOLDERNAME = 'CS231n_project/'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4353,
     "status": "ok",
     "timestamp": 1653204890527,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "ejjKJYC2YffB",
    "outputId": "7a1aad97-7fc6-4c21-fa04-24f4508284e0"
   },
   "outputs": [],
   "source": [
    "# !pip install torch==1.7 torchvision==0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6003,
     "status": "ok",
     "timestamp": 1653204896527,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "TzJV-LLVhBt5",
    "outputId": "03468936-f099-4c8f-935b-9dfc257e456a"
   },
   "outputs": [],
   "source": [
    "# %cd approx/src/pytorch/cpp\n",
    "# !python setup.py install\n",
    "# %cd ../../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1653204897473,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "uGvmWqNZD2hh",
    "outputId": "fd0ce3ef-78c9-4a72-bef1-a3b94a03a0e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from conv_norm import PreConv\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from utils import ImportanceSampler\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653204897475,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "BMatykiuGnJT"
   },
   "outputs": [],
   "source": [
    "from utils import get_accuracy, load_dataset\n",
    "from models import get_model\n",
    "check_accuracy = lambda loader, model: get_accuracy(loader, model, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1653206021690,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "dLHtcW9UHqOt"
   },
   "outputs": [],
   "source": [
    "def train_model(model_name, dataset_name, model_params={}, hyperparams={}):\n",
    "\n",
    "  learning_rate = hyperparams.get('lr', 1e-3)\n",
    "  num_epochs = hyperparams.get('num_epochs', 10)\n",
    "  weight_decay = hyperparams.get('weight_decay', 0)\n",
    "  train_ratio = hyperparams.get('train_ratio', 0.8)\n",
    "  batch_size = hyperparams.get('batch_size', 64)\n",
    "  seed = hyperparams.get('seed', 0)\n",
    "  imp_sampling = model_params.get('importance_sampling', False)\n",
    "  gamma = model_params.get('gamma', 0.9)\n",
    "\n",
    "  torch.manual_seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  loader_train, loader_val, loader_test, num_train, num_channels = load_dataset(dataset_name, train_ratio, batch_size)\n",
    "  model = get_model(model_name, model_params, learning_rate, loader_train, num_channels, device)\n",
    "\n",
    "  print(\"Model architecture:\")\n",
    "  print(model)\n",
    "\n",
    "  print(f'INFO: Training {model_name} on {dataset_name} with lr {learning_rate}, num_epochs={num_epochs}, weight_decay={weight_decay}')\n",
    "\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "\n",
    "  epoch_vals = []\n",
    "  \n",
    "  weight = torch.tensor([1.0]*num_train)\n",
    "\n",
    "  t_acc, t_loss = check_accuracy(loader_train, model)\n",
    "  val_acc, val_loss = check_accuracy(loader_val, model)\n",
    "  \n",
    "  start = timer()\n",
    "  c_time = timer()-start\n",
    "\n",
    "  print(f'Plot: Train, {0}, {t_loss:.3f}, {t_acc:.2f}, {c_time:.1f}')\n",
    "  print(f'Plot: Val, {0}, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  for e in range(num_epochs):\n",
    "    model.train()\n",
    "    doUniform = (e == 0) or (imp_sampling == False)\n",
    "    loader_train_sampled = loader_train\n",
    "    if not doUniform:\n",
    "      train_sampler = ImportanceSampler(num_train, weight, batch_size)\n",
    "      loader_train_sampled, _, _, _, _ = load_dataset(dataset_name, train_ratio, batch_size, train_sampler)\n",
    "    \n",
    "    for t, tpl in enumerate(loader_train_sampled):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()  # put model to training mode\n",
    "        x = tpl[0].to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "        y = tpl[1].to(device=device, dtype=torch.long)\n",
    "\n",
    "        scores = model(x)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not doUniform:\n",
    "          idx = tpl[2]\n",
    "          weight[idx] = gamma * weight[idx] + (1 - gamma) * float(loss)\n",
    "\n",
    "    t_acc, t_loss = check_accuracy(loader_train, model)\n",
    "    model.eval()\n",
    "    val_acc, val_loss = check_accuracy(loader_val, model)\n",
    "    c_time = timer()-start\n",
    "\n",
    "    print(f'Plot: Train, {e+1}, {t_loss:.3f}, {t_acc:.2f}, {c_time:.1f}')\n",
    "    print(f'Plot: Val, {e+1}, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  test_acc, test_loss = check_accuracy(loader_test, model)\n",
    "  print(f'Plot: Test, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradinit_params = {\n",
    "#     \"gradinit_iters\": 50,\n",
    "#     \"gradinit_alg\": \"adam\", #sgd\n",
    "#     \"gradinit_lr\": 1e-2,\n",
    "#     \"gradinit_grad_clip\": 100,\n",
    "# }\n",
    "model_params = {\n",
    "#     \"gradinit\": gradinit_params,\n",
    "    \"convnorm\" : {\"mode_conv\": [('first_frac', 0.25)], \"mode_bn\": [('first_frac', 0.25)]},\n",
    "    # \"approx_mult\" : 0.2,\n",
    "    # \"importance_sampling\" : True,\n",
    "    # \"gamma\" : 0.9\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-5,\n",
    "    \"num_epochs\" : 75,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 1024,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_setup():\n",
    "#     modeList = [[('last_num', 1)], [('last_frac', 0.25)], [('last_frac', 0.5)], [('last_frac', 0.75)]][1:]\n",
    "#     for mode in modeList:\n",
    "#         model_params['convnorm'][\"mode_conv\"] = mode\n",
    "#         model_params['convnorm'][\"mode_bn\"] = mode\n",
    "#         train_model('VGG16', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "# test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_setup():\n",
    "#     modeList = [[('first_frac', 0.25)]]\n",
    "#     for mode in modeList:\n",
    "#         model_params['convnorm'][\"mode_conv\"] = mode\n",
    "#         model_params['convnorm'][\"mode_bn\"] = mode\n",
    "#         train_model('VGG16', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "# test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "GradInit Args: adam, Iters 200, lr 1e-05\n",
      "GradInit: Iter 10, obj iters 10, eta 1.000e-01, constraint count 0 loss: 2.369e+25 (2.569e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.369e+24 (2.569e+24), total gnorm: 1.498e+03 (1.496e+03)\ts_max: 1.00e+00\ts_min: 1.00e+00\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 1.00e+00\ts_weight_mean: 1.00e+00\t\n",
      "GradInit: Iter 20, obj iters 20, eta 1.000e-01, constraint count 0 loss: 1.532e+25 (2.359e+25), init loss: 6.911e+00 (6.911e+00), update loss 1.532e+24 (2.359e+24), total gnorm: 1.471e+03 (1.493e+03)\ts_max: 1.00e+00\ts_min: 1.00e+00\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 1.00e+00\ts_weight_mean: 1.00e+00\t\n",
      "GradInit: Iter 30, obj iters 30, eta 1.000e-01, constraint count 0 loss: 1.968e+25 (2.454e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.968e+24 (2.454e+24), total gnorm: 1.523e+03 (1.498e+03)\ts_max: 1.00e+00\ts_min: 1.00e+00\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 1.00e+00\ts_weight_mean: 1.00e+00\t\n",
      "GradInit: Iter 40, obj iters 40, eta 1.000e-01, constraint count 0 loss: 1.461e+25 (2.348e+25), init loss: 6.911e+00 (6.911e+00), update loss 1.461e+24 (2.348e+24), total gnorm: 1.503e+03 (1.495e+03)\ts_max: 1.00e+00\ts_min: 1.00e+00\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 1.00e+00\ts_weight_mean: 1.00e+00\t\n",
      "GradInit: Iter 50, obj iters 50, eta 1.000e-01, constraint count 0 loss: 1.162e+25 (2.406e+25), init loss: 6.911e+00 (6.911e+00), update loss 1.162e+24 (2.406e+24), total gnorm: 1.520e+03 (1.494e+03)\ts_max: 1.00e+00\ts_min: 1.00e+00\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 1.00e+00\ts_weight_mean: 1.00e+00\t\n",
      "GradInit: Iter 60, obj iters 60, eta 1.000e-01, constraint count 0 loss: 2.096e+25 (2.360e+25), init loss: 6.911e+00 (6.911e+00), update loss 2.096e+24 (2.360e+24), total gnorm: 1.485e+03 (1.494e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 1.00e+00\t\n",
      "GradInit: Iter 70, obj iters 70, eta 1.000e-01, constraint count 0 loss: 1.369e+25 (2.497e+25), init loss: 6.911e+00 (6.910e+00), update loss 1.369e+24 (2.497e+24), total gnorm: 1.465e+03 (1.492e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 80, obj iters 80, eta 1.000e-01, constraint count 0 loss: 3.149e+25 (2.572e+25), init loss: 6.910e+00 (6.910e+00), update loss 3.149e+24 (2.572e+24), total gnorm: 1.468e+03 (1.493e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 90, obj iters 90, eta 1.000e-01, constraint count 0 loss: 1.892e+25 (2.503e+25), init loss: 6.911e+00 (6.911e+00), update loss 1.892e+24 (2.503e+24), total gnorm: 1.505e+03 (1.492e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 100, obj iters 100, eta 1.000e-01, constraint count 0 loss: 2.418e+25 (2.528e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.418e+24 (2.528e+24), total gnorm: 1.485e+03 (1.490e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 110, obj iters 110, eta 1.000e-01, constraint count 0 loss: 3.643e+25 (2.501e+25), init loss: 6.909e+00 (6.910e+00), update loss 3.643e+24 (2.501e+24), total gnorm: 1.511e+03 (1.490e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 120, obj iters 120, eta 1.000e-01, constraint count 0 loss: 2.161e+25 (2.469e+25), init loss: 6.911e+00 (6.910e+00), update loss 2.161e+24 (2.469e+24), total gnorm: 1.485e+03 (1.489e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 130, obj iters 130, eta 1.000e-01, constraint count 0 loss: 2.571e+25 (2.477e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.571e+24 (2.477e+24), total gnorm: 1.483e+03 (1.488e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 140, obj iters 140, eta 1.000e-01, constraint count 0 loss: 8.435e+25 (2.483e+25), init loss: 6.909e+00 (6.910e+00), update loss 8.435e+24 (2.483e+24), total gnorm: 1.483e+03 (1.488e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 150, obj iters 150, eta 1.000e-01, constraint count 0 loss: 2.466e+25 (2.486e+25), init loss: 6.911e+00 (6.910e+00), update loss 2.466e+24 (2.486e+24), total gnorm: 1.474e+03 (1.487e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 160, obj iters 160, eta 1.000e-01, constraint count 0 loss: 1.857e+25 (2.469e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.857e+24 (2.469e+24), total gnorm: 1.499e+03 (1.486e+03)\ts_max: 1.00e+00\ts_min: 9.98e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.98e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 170, obj iters 170, eta 1.000e-01, constraint count 0 loss: 1.039e+25 (2.446e+25), init loss: 6.911e+00 (6.910e+00), update loss 1.039e+24 (2.446e+24), total gnorm: 1.451e+03 (1.486e+03)\ts_max: 1.00e+00\ts_min: 9.98e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.98e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 180, obj iters 180, eta 1.000e-01, constraint count 0 loss: 4.436e+25 (2.469e+25), init loss: 6.910e+00 (6.910e+00), update loss 4.436e+24 (2.469e+24), total gnorm: 1.431e+03 (1.484e+03)\ts_max: 1.00e+00\ts_min: 9.98e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.98e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 190, obj iters 190, eta 1.000e-01, constraint count 0 loss: 1.724e+25 (2.433e+25), init loss: 6.911e+00 (6.910e+00), update loss 1.724e+24 (2.433e+24), total gnorm: 1.486e+03 (1.484e+03)\ts_max: 1.00e+00\ts_min: 9.98e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.98e-01\ts_weight_mean: 9.98e-01\t\n",
      "GradInit: Iter 200, obj iters 200, eta 1.000e-01, constraint count 0 loss: 4.123e+25 (2.426e+25), init loss: 6.910e+00 (6.910e+00), update loss 4.123e+24 (2.426e+24), total gnorm: 1.467e+03 (1.483e+03)\ts_max: 1.00e+00\ts_min: 9.98e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.98e-01\ts_weight_mean: 9.98e-01\t\n",
      "Model architecture:\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "INFO: Training VGG16 on CIFAR100 with lr 3e-05, num_epochs=60, weight_decay=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 0, 6.907, 0.00, 0.0\n",
      "Plot: Val, 0, 6.909, 0.00, 0.0\n",
      "Plot: Train, 1, 4.691, 0.97, 37.6\n",
      "Plot: Val, 1, 4.684, 1.14, 37.6\n",
      "Plot: Train, 2, 4.319, 2.59, 75.8\n",
      "Plot: Val, 2, 4.433, 2.48, 75.8\n",
      "Plot: Train, 3, 4.065, 6.79, 114.1\n",
      "Plot: Val, 3, 4.070, 6.42, 114.1\n",
      "Plot: Train, 4, 3.719, 9.35, 152.3\n",
      "Plot: Val, 4, 3.934, 8.95, 152.3\n",
      "Plot: Train, 5, 3.609, 12.16, 188.9\n",
      "Plot: Val, 5, 3.611, 11.73, 188.9\n",
      "Plot: Train, 6, 3.518, 14.88, 224.9\n",
      "Plot: Val, 6, 3.581, 14.10, 224.9\n",
      "Plot: Train, 7, 3.569, 17.48, 260.6\n",
      "Plot: Val, 7, 3.592, 16.35, 260.6\n",
      "Plot: Train, 8, 3.162, 19.11, 296.4\n",
      "Plot: Val, 8, 3.499, 17.80, 296.4\n",
      "Plot: Train, 9, 3.114, 21.90, 332.4\n",
      "Plot: Val, 9, 3.371, 20.34, 332.4\n",
      "Plot: Train, 10, 3.105, 23.21, 368.7\n",
      "Plot: Val, 10, 3.111, 21.00, 368.7\n",
      "Plot: Train, 11, 2.991, 21.70, 405.2\n",
      "Plot: Val, 11, 3.278, 19.26, 405.2\n",
      "Plot: Train, 12, 2.674, 26.87, 442.4\n",
      "Plot: Val, 12, 3.248, 23.32, 442.4\n",
      "Plot: Train, 13, 2.855, 28.15, 480.0\n",
      "Plot: Val, 13, 2.967, 24.28, 480.0\n",
      "Plot: Train, 14, 2.488, 29.73, 517.9\n",
      "Plot: Val, 14, 3.044, 25.41, 517.9\n",
      "Plot: Train, 15, 2.942, 28.10, 556.1\n",
      "Plot: Val, 15, 3.233, 23.38, 556.1\n",
      "Plot: Train, 16, 2.602, 31.35, 594.4\n",
      "Plot: Val, 16, 2.905, 25.41, 594.4\n",
      "Plot: Train, 17, 2.876, 33.95, 632.5\n",
      "Plot: Val, 17, 2.889, 27.45, 632.5\n",
      "Plot: Train, 18, 2.579, 32.80, 670.4\n",
      "Plot: Val, 18, 2.943, 26.61, 670.4\n",
      "Plot: Train, 19, 2.151, 34.69, 708.3\n",
      "Plot: Val, 19, 3.020, 27.47, 708.3\n",
      "Plot: Train, 20, 2.286, 34.71, 746.2\n",
      "Plot: Val, 20, 3.012, 26.78, 746.2\n",
      "Plot: Train, 21, 2.528, 38.53, 784.1\n",
      "Plot: Val, 21, 2.976, 28.95, 784.1\n",
      "Plot: Train, 22, 2.006, 40.62, 822.4\n",
      "Plot: Val, 22, 2.816, 29.59, 822.4\n",
      "Plot: Train, 23, 2.409, 42.80, 860.7\n",
      "Plot: Val, 23, 2.744, 30.03, 860.7\n",
      "Plot: Train, 24, 1.997, 45.39, 898.8\n",
      "Plot: Val, 24, 2.916, 31.08, 898.8\n",
      "Plot: Train, 25, 1.962, 45.12, 936.8\n",
      "Plot: Val, 25, 2.992, 30.25, 936.8\n",
      "Plot: Train, 26, 1.698, 46.37, 974.7\n",
      "Plot: Val, 26, 2.908, 29.52, 974.7\n",
      "Plot: Train, 27, 2.009, 46.21, 1012.7\n",
      "Plot: Val, 27, 2.945, 28.45, 1012.7\n",
      "Plot: Train, 28, 1.636, 48.68, 1051.2\n",
      "Plot: Val, 28, 2.849, 28.87, 1051.2\n",
      "Plot: Train, 29, 1.529, 53.30, 1089.6\n",
      "Plot: Val, 29, 3.129, 29.99, 1089.6\n",
      "Plot: Train, 30, 1.526, 53.79, 1127.9\n",
      "Plot: Val, 30, 3.021, 29.41, 1127.9\n",
      "Plot: Train, 31, 1.772, 55.72, 1166.3\n",
      "Plot: Val, 31, 2.936, 28.88, 1166.3\n",
      "Plot: Train, 32, 1.504, 59.21, 1204.7\n",
      "Plot: Val, 32, 3.384, 29.23, 1204.7\n",
      "Plot: Train, 33, 1.598, 53.86, 1243.1\n",
      "Plot: Val, 33, 3.294, 27.19, 1243.1\n",
      "Plot: Train, 34, 1.149, 63.38, 1281.5\n",
      "Plot: Val, 34, 3.172, 29.94, 1281.5\n",
      "Plot: Train, 35, 1.226, 67.52, 1319.9\n",
      "Plot: Val, 35, 3.513, 29.39, 1319.9\n",
      "Plot: Train, 36, 1.172, 68.15, 1358.4\n",
      "Plot: Val, 36, 3.261, 30.19, 1358.4\n",
      "Plot: Train, 37, 1.041, 73.13, 1396.8\n",
      "Plot: Val, 37, 3.572, 30.12, 1396.8\n",
      "Plot: Train, 38, 1.187, 63.60, 1435.3\n",
      "Plot: Val, 38, 4.076, 25.96, 1435.3\n",
      "Plot: Train, 39, 1.254, 68.21, 1473.7\n",
      "Plot: Val, 39, 4.263, 26.86, 1473.7\n",
      "Plot: Train, 40, 0.823, 73.11, 1512.2\n",
      "Plot: Val, 40, 3.604, 28.08, 1512.2\n",
      "Plot: Train, 41, 0.765, 78.56, 1549.8\n",
      "Plot: Val, 41, 4.022, 28.96, 1549.8\n",
      "Plot: Train, 42, 0.430, 83.75, 1586.1\n",
      "Plot: Val, 42, 4.064, 29.15, 1586.1\n",
      "Plot: Train, 43, 0.499, 84.77, 1622.0\n",
      "Plot: Val, 43, 4.385, 28.49, 1622.0\n",
      "Plot: Train, 44, 0.606, 82.06, 1657.9\n",
      "Plot: Val, 44, 4.796, 27.26, 1657.9\n",
      "Plot: Train, 45, 0.472, 83.94, 1693.9\n",
      "Plot: Val, 45, 4.331, 27.67, 1693.9\n",
      "Plot: Train, 46, 0.427, 82.34, 1729.9\n",
      "Plot: Val, 46, 5.040, 26.34, 1729.9\n",
      "Plot: Train, 47, 0.523, 87.36, 1765.7\n",
      "Plot: Val, 47, 5.285, 27.31, 1765.7\n",
      "Plot: Train, 48, 0.490, 83.72, 1801.5\n",
      "Plot: Val, 48, 5.390, 26.39, 1801.5\n",
      "Plot: Train, 49, 0.305, 88.69, 1837.4\n",
      "Plot: Val, 49, 6.331, 26.00, 1837.4\n",
      "Plot: Train, 50, 0.308, 90.00, 1873.4\n",
      "Plot: Val, 50, 5.622, 26.33, 1873.4\n",
      "Plot: Train, 51, 0.233, 91.95, 1909.5\n",
      "Plot: Val, 51, 5.507, 27.14, 1909.5\n",
      "Plot: Train, 52, 0.280, 94.64, 1946.0\n",
      "Plot: Val, 52, 6.011, 26.93, 1946.0\n",
      "Plot: Train, 53, 0.095, 96.62, 1982.8\n",
      "Plot: Val, 53, 5.641, 27.31, 1982.8\n",
      "Plot: Train, 54, 0.152, 96.19, 2020.4\n",
      "Plot: Val, 54, 6.126, 27.51, 2020.4\n",
      "Plot: Train, 55, 0.107, 96.06, 2058.2\n",
      "Plot: Val, 55, 6.925, 27.07, 2058.2\n",
      "Plot: Train, 56, 0.117, 97.30, 2096.4\n",
      "Plot: Val, 56, 6.166, 27.29, 2096.4\n",
      "Plot: Train, 57, 0.121, 94.66, 2134.9\n",
      "Plot: Val, 57, 5.529, 27.54, 2134.9\n",
      "Plot: Train, 58, 0.099, 97.55, 2173.2\n",
      "Plot: Val, 58, 7.228, 26.42, 2173.2\n",
      "Plot: Train, 59, 0.079, 97.55, 2211.1\n",
      "Plot: Val, 59, 6.798, 26.66, 2211.1\n",
      "Plot: Train, 60, 0.068, 98.34, 2249.1\n",
      "Plot: Val, 60, 6.760, 27.37, 2249.1\n",
      "Plot: Test, 6.760, 27.37, 2249.1\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "GradInit Args: adam, Iters 200, lr 0.0001\n",
      "GradInit: Iter 10, obj iters 10, eta 1.000e-01, constraint count 0 loss: 2.368e+25 (2.565e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.368e+24 (2.565e+24), total gnorm: 1.483e+03 (1.488e+03)\ts_max: 1.00e+00\ts_min: 9.99e-01\ts_mean: 1.00e+00\ts_weight_max: 1.00e+00\ts_weight_min: 9.99e-01\ts_weight_mean: 9.99e-01\t\n",
      "GradInit: Iter 20, obj iters 20, eta 1.000e-01, constraint count 0 loss: 1.533e+25 (2.363e+25), init loss: 6.911e+00 (6.911e+00), update loss 1.533e+24 (2.363e+24), total gnorm: 1.440e+03 (1.478e+03)\ts_max: 1.00e+00\ts_min: 9.98e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.98e-01\ts_weight_mean: 9.98e-01\t\n",
      "GradInit: Iter 30, obj iters 30, eta 1.000e-01, constraint count 0 loss: 1.976e+25 (2.464e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.976e+24 (2.464e+24), total gnorm: 1.475e+03 (1.474e+03)\ts_max: 1.00e+00\ts_min: 9.97e-01\ts_mean: 9.99e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.97e-01\ts_weight_mean: 9.98e-01\t\n",
      "GradInit: Iter 40, obj iters 40, eta 1.000e-01, constraint count 0 loss: 1.480e+25 (2.362e+25), init loss: 6.911e+00 (6.910e+00), update loss 1.480e+24 (2.362e+24), total gnorm: 1.440e+03 (1.464e+03)\ts_max: 1.00e+00\ts_min: 9.96e-01\ts_mean: 9.98e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.96e-01\ts_weight_mean: 9.97e-01\t\n",
      "GradInit: Iter 50, obj iters 50, eta 1.000e-01, constraint count 0 loss: 1.182e+25 (2.423e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.182e+24 (2.423e+24), total gnorm: 1.441e+03 (1.455e+03)\ts_max: 1.00e+00\ts_min: 9.95e-01\ts_mean: 9.98e-01\ts_weight_max: 1.00e+00\ts_weight_min: 9.95e-01\ts_weight_mean: 9.96e-01\t\n",
      "GradInit: Iter 60, obj iters 60, eta 1.000e-01, constraint count 0 loss: 2.125e+25 (2.380e+25), init loss: 6.911e+00 (6.910e+00), update loss 2.125e+24 (2.380e+24), total gnorm: 1.392e+03 (1.446e+03)\ts_max: 1.01e+00\ts_min: 9.94e-01\ts_mean: 9.98e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.94e-01\ts_weight_mean: 9.95e-01\t\n",
      "GradInit: Iter 70, obj iters 70, eta 1.000e-01, constraint count 0 loss: 1.389e+25 (2.524e+25), init loss: 6.911e+00 (6.910e+00), update loss 1.389e+24 (2.524e+24), total gnorm: 1.359e+03 (1.437e+03)\ts_max: 1.01e+00\ts_min: 9.93e-01\ts_mean: 9.97e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.93e-01\ts_weight_mean: 9.94e-01\t\n",
      "GradInit: Iter 80, obj iters 80, eta 1.000e-01, constraint count 0 loss: 3.230e+25 (2.605e+25), init loss: 6.910e+00 (6.910e+00), update loss 3.230e+24 (2.605e+24), total gnorm: 1.346e+03 (1.430e+03)\ts_max: 1.01e+00\ts_min: 9.92e-01\ts_mean: 9.97e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.92e-01\ts_weight_mean: 9.94e-01\t\n",
      "GradInit: Iter 90, obj iters 90, eta 1.000e-01, constraint count 0 loss: 1.925e+25 (2.536e+25), init loss: 6.911e+00 (6.910e+00), update loss 1.925e+24 (2.536e+24), total gnorm: 1.366e+03 (1.422e+03)\ts_max: 1.01e+00\ts_min: 9.91e-01\ts_mean: 9.96e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.91e-01\ts_weight_mean: 9.93e-01\t\n",
      "GradInit: Iter 100, obj iters 100, eta 1.000e-01, constraint count 0 loss: 2.501e+25 (2.565e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.501e+24 (2.565e+24), total gnorm: 1.333e+03 (1.412e+03)\ts_max: 1.01e+00\ts_min: 9.90e-01\ts_mean: 9.96e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.90e-01\ts_weight_mean: 9.92e-01\t\n",
      "GradInit: Iter 110, obj iters 110, eta 1.000e-01, constraint count 0 loss: 3.800e+25 (2.541e+25), init loss: 6.909e+00 (6.910e+00), update loss 3.800e+24 (2.541e+24), total gnorm: 1.342e+03 (1.404e+03)\ts_max: 1.01e+00\ts_min: 9.89e-01\ts_mean: 9.96e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.89e-01\ts_weight_mean: 9.91e-01\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradInit: Iter 120, obj iters 120, eta 1.000e-01, constraint count 0 loss: 2.218e+25 (2.511e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.218e+24 (2.511e+24), total gnorm: 1.305e+03 (1.396e+03)\ts_max: 1.01e+00\ts_min: 9.88e-01\ts_mean: 9.95e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.88e-01\ts_weight_mean: 9.90e-01\t\n",
      "GradInit: Iter 130, obj iters 130, eta 1.000e-01, constraint count 0 loss: 2.653e+25 (2.523e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.653e+24 (2.523e+24), total gnorm: 1.289e+03 (1.389e+03)\ts_max: 1.01e+00\ts_min: 9.87e-01\ts_mean: 9.95e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.87e-01\ts_weight_mean: 9.90e-01\t\n",
      "GradInit: Iter 140, obj iters 140, eta 1.000e-01, constraint count 0 loss: 8.839e+25 (2.532e+25), init loss: 6.909e+00 (6.910e+00), update loss 8.839e+24 (2.532e+24), total gnorm: 1.274e+03 (1.381e+03)\ts_max: 1.01e+00\ts_min: 9.86e-01\ts_mean: 9.94e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.86e-01\ts_weight_mean: 9.89e-01\t\n",
      "GradInit: Iter 150, obj iters 150, eta 1.000e-01, constraint count 0 loss: 2.537e+25 (2.538e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.537e+24 (2.538e+24), total gnorm: 1.251e+03 (1.372e+03)\ts_max: 1.01e+00\ts_min: 9.85e-01\ts_mean: 9.94e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.85e-01\ts_weight_mean: 9.88e-01\t\n",
      "GradInit: Iter 160, obj iters 160, eta 1.000e-01, constraint count 0 loss: 1.964e+25 (2.523e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.964e+24 (2.523e+24), total gnorm: 1.259e+03 (1.365e+03)\ts_max: 1.02e+00\ts_min: 9.84e-01\ts_mean: 9.94e-01\ts_weight_max: 1.02e+00\ts_weight_min: 9.84e-01\ts_weight_mean: 9.87e-01\t\n",
      "GradInit: Iter 170, obj iters 170, eta 1.000e-01, constraint count 0 loss: 1.058e+25 (2.502e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.058e+24 (2.502e+24), total gnorm: 1.205e+03 (1.357e+03)\ts_max: 1.02e+00\ts_min: 9.83e-01\ts_mean: 9.93e-01\ts_weight_max: 1.02e+00\ts_weight_min: 9.83e-01\ts_weight_mean: 9.86e-01\t\n",
      "GradInit: Iter 180, obj iters 180, eta 1.000e-01, constraint count 0 loss: 4.686e+25 (2.528e+25), init loss: 6.910e+00 (6.910e+00), update loss 4.686e+24 (2.528e+24), total gnorm: 1.176e+03 (1.348e+03)\ts_max: 1.02e+00\ts_min: 9.82e-01\ts_mean: 9.93e-01\ts_weight_max: 1.02e+00\ts_weight_min: 9.82e-01\ts_weight_mean: 9.85e-01\t\n",
      "GradInit: Iter 190, obj iters 190, eta 1.000e-01, constraint count 0 loss: 1.778e+25 (2.493e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.778e+24 (2.493e+24), total gnorm: 1.207e+03 (1.341e+03)\ts_max: 1.02e+00\ts_min: 9.81e-01\ts_mean: 9.92e-01\ts_weight_max: 1.02e+00\ts_weight_min: 9.81e-01\ts_weight_mean: 9.85e-01\t\n",
      "GradInit: Iter 200, obj iters 200, eta 1.000e-01, constraint count 0 loss: 4.282e+25 (2.487e+25), init loss: 6.909e+00 (6.910e+00), update loss 4.282e+24 (2.487e+24), total gnorm: 1.179e+03 (1.333e+03)\ts_max: 1.02e+00\ts_min: 9.80e-01\ts_mean: 9.92e-01\ts_weight_max: 1.02e+00\ts_weight_min: 9.80e-01\ts_weight_mean: 9.84e-01\t\n",
      "Model architecture:\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "INFO: Training VGG16 on CIFAR100 with lr 3e-05, num_epochs=60, weight_decay=0\n",
      "Plot: Train, 0, 6.907, 0.00, 0.0\n",
      "Plot: Val, 0, 6.909, 0.00, 0.0\n",
      "Plot: Train, 1, 4.690, 0.97, 37.6\n",
      "Plot: Val, 1, 4.685, 1.14, 37.6\n",
      "Plot: Train, 2, 4.389, 2.05, 75.5\n",
      "Plot: Val, 2, 4.485, 2.03, 75.5\n",
      "Plot: Train, 3, 4.185, 5.95, 113.8\n",
      "Plot: Val, 3, 4.163, 5.79, 113.8\n",
      "Plot: Train, 4, 3.858, 7.80, 152.1\n",
      "Plot: Val, 4, 4.035, 7.50, 152.1\n",
      "Plot: Train, 5, 3.635, 11.34, 190.4\n",
      "Plot: Val, 5, 3.671, 10.85, 190.4\n",
      "Plot: Train, 6, 3.513, 14.06, 228.6\n",
      "Plot: Val, 6, 3.612, 13.72, 228.6\n",
      "Plot: Train, 7, 3.576, 16.29, 267.0\n",
      "Plot: Val, 7, 3.660, 15.12, 267.0\n",
      "Plot: Train, 8, 3.266, 17.36, 305.2\n",
      "Plot: Val, 8, 3.572, 16.45, 305.2\n",
      "Plot: Train, 9, 3.183, 20.44, 343.5\n",
      "Plot: Val, 9, 3.422, 19.04, 343.5\n",
      "Plot: Train, 10, 3.193, 21.95, 380.9\n",
      "Plot: Val, 10, 3.164, 20.52, 380.9\n",
      "Plot: Train, 11, 2.921, 22.68, 417.1\n",
      "Plot: Val, 11, 3.197, 20.53, 417.1\n",
      "Plot: Train, 12, 2.732, 25.43, 452.9\n",
      "Plot: Val, 12, 3.291, 22.61, 452.9\n",
      "Plot: Train, 13, 2.821, 26.95, 488.6\n",
      "Plot: Val, 13, 2.993, 23.32, 488.6\n",
      "Plot: Train, 14, 2.636, 26.76, 524.3\n",
      "Plot: Val, 14, 3.124, 23.50, 524.3\n",
      "Plot: Train, 15, 3.140, 25.80, 559.9\n",
      "Plot: Val, 15, 3.397, 21.97, 559.9\n",
      "Plot: Train, 16, 2.556, 30.54, 595.6\n",
      "Plot: Val, 16, 2.862, 25.54, 595.6\n",
      "Plot: Train, 17, 2.944, 32.37, 631.4\n",
      "Plot: Val, 17, 2.951, 26.69, 631.4\n",
      "Plot: Train, 18, 2.641, 31.55, 667.2\n",
      "Plot: Val, 18, 2.988, 25.90, 667.2\n",
      "Plot: Train, 19, 2.036, 34.65, 702.9\n",
      "Plot: Val, 19, 2.959, 28.01, 702.9\n",
      "Plot: Train, 20, 2.311, 34.27, 738.5\n",
      "Plot: Val, 20, 3.025, 27.09, 738.5\n",
      "Plot: Train, 21, 2.522, 37.84, 774.4\n",
      "Plot: Val, 21, 2.951, 28.84, 774.4\n",
      "Plot: Train, 22, 2.136, 38.85, 810.3\n",
      "Plot: Val, 22, 2.915, 28.98, 810.3\n",
      "Plot: Train, 23, 2.352, 40.10, 846.5\n",
      "Plot: Val, 23, 2.727, 29.39, 846.5\n",
      "Plot: Train, 24, 2.087, 43.12, 883.0\n",
      "Plot: Val, 24, 2.895, 30.24, 883.0\n",
      "Plot: Train, 25, 2.167, 43.39, 920.1\n",
      "Plot: Val, 25, 3.031, 29.55, 920.1\n",
      "Plot: Train, 26, 1.986, 40.66, 957.6\n",
      "Plot: Val, 26, 3.104, 26.86, 957.6\n",
      "Plot: Train, 27, 2.085, 45.55, 995.5\n",
      "Plot: Val, 27, 2.886, 29.15, 995.5\n",
      "Plot: Train, 28, 1.536, 46.70, 1033.8\n",
      "Plot: Val, 28, 2.983, 28.95, 1033.8\n",
      "Plot: Train, 29, 1.692, 51.21, 1072.1\n",
      "Plot: Val, 29, 3.004, 29.96, 1072.1\n",
      "Plot: Train, 30, 1.723, 49.43, 1110.2\n",
      "Plot: Val, 30, 3.088, 28.07, 1110.2\n",
      "Plot: Train, 31, 1.550, 55.71, 1148.2\n",
      "Plot: Val, 31, 2.773, 30.54, 1148.2\n",
      "Plot: Train, 32, 1.595, 54.53, 1186.2\n",
      "Plot: Val, 32, 3.391, 28.88, 1186.2\n",
      "Plot: Train, 33, 1.512, 54.04, 1224.1\n",
      "Plot: Val, 33, 3.235, 27.49, 1224.1\n",
      "Plot: Train, 34, 1.138, 61.95, 1262.3\n",
      "Plot: Val, 34, 3.070, 29.95, 1262.3\n",
      "Plot: Train, 35, 1.240, 65.24, 1300.7\n",
      "Plot: Val, 35, 3.340, 29.23, 1300.7\n",
      "Plot: Train, 36, 1.090, 65.94, 1338.8\n",
      "Plot: Val, 36, 3.287, 29.97, 1338.8\n",
      "Plot: Train, 37, 1.608, 61.02, 1376.9\n",
      "Plot: Val, 37, 3.720, 27.37, 1376.9\n",
      "Plot: Train, 38, 1.181, 67.62, 1414.8\n",
      "Plot: Val, 38, 3.667, 27.87, 1414.8\n",
      "Plot: Train, 39, 1.024, 69.96, 1453.0\n",
      "Plot: Val, 39, 3.979, 27.80, 1453.0\n",
      "Plot: Train, 40, 0.912, 71.23, 1491.5\n",
      "Plot: Val, 40, 3.760, 27.71, 1491.5\n",
      "Plot: Train, 41, 0.772, 74.47, 1529.9\n",
      "Plot: Val, 41, 3.914, 27.72, 1529.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 45, 0.468, 83.50, 1682.4\n",
      "Plot: Val, 45, 4.255, 28.05, 1682.4\n",
      "Plot: Train, 46, 0.680, 75.77, 1720.7\n",
      "Plot: Val, 46, 5.302, 25.92, 1720.7\n",
      "Plot: Train, 47, 0.669, 84.06, 1758.7\n",
      "Plot: Val, 47, 5.288, 26.94, 1758.7\n",
      "Plot: Train, 48, 0.358, 82.45, 1796.7\n",
      "Plot: Val, 48, 5.139, 26.76, 1796.7\n",
      "Plot: Train, 49, 0.283, 91.38, 1834.6\n",
      "Plot: Val, 49, 6.066, 26.98, 1834.6\n",
      "Plot: Train, 50, 0.245, 90.07, 1872.6\n",
      "Plot: Val, 50, 5.691, 26.11, 1872.6\n",
      "Plot: Train, 51, 0.359, 84.14, 1911.0\n",
      "Plot: Val, 51, 5.513, 24.67, 1911.0\n",
      "Plot: Train, 52, 0.327, 93.68, 1949.5\n",
      "Plot: Val, 52, 5.595, 27.07, 1949.5\n",
      "Plot: Train, 53, 0.161, 92.97, 1988.0\n",
      "Plot: Val, 53, 6.467, 26.05, 1988.0\n",
      "Plot: Train, 54, 0.283, 93.48, 2026.4\n",
      "Plot: Val, 54, 6.356, 26.40, 2026.4\n",
      "Plot: Train, 55, 0.109, 96.49, 2064.7\n",
      "Plot: Val, 55, 6.971, 27.36, 2064.7\n",
      "Plot: Train, 56, 0.263, 94.22, 2103.1\n",
      "Plot: Val, 56, 6.196, 25.76, 2103.1\n",
      "Plot: Train, 57, 0.074, 98.04, 2141.4\n",
      "Plot: Val, 57, 6.695, 27.02, 2141.4\n",
      "Plot: Train, 58, 0.145, 94.64, 2179.8\n",
      "Plot: Val, 58, 6.853, 26.04, 2179.8\n",
      "Plot: Train, 59, 0.066, 97.22, 2218.1\n",
      "Plot: Val, 59, 6.477, 27.07, 2218.1\n",
      "Plot: Train, 60, 0.043, 98.06, 2256.4\n",
      "Plot: Val, 60, 6.890, 27.51, 2256.4\n",
      "Plot: Test, 6.890, 27.51, 2256.4\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "GradInit Args: adam, Iters 200, lr 0.001\n",
      "GradInit: Iter 10, obj iters 10, eta 1.000e-01, constraint count 0 loss: 2.406e+25 (2.593e+25), init loss: 6.910e+00 (6.910e+00), update loss 2.406e+24 (2.593e+24), total gnorm: 1.339e+03 (1.414e+03)\ts_max: 1.01e+00\ts_min: 9.90e-01\ts_mean: 9.96e-01\ts_weight_max: 1.01e+00\ts_weight_min: 9.90e-01\ts_weight_mean: 9.92e-01\t\n",
      "GradInit: Iter 20, obj iters 20, eta 1.000e-01, constraint count 0 loss: 1.587e+25 (2.410e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.587e+24 (2.410e+24), total gnorm: 1.163e+03 (1.330e+03)\ts_max: 1.02e+00\ts_min: 9.80e-01\ts_mean: 9.92e-01\ts_weight_max: 1.02e+00\ts_weight_min: 9.80e-01\ts_weight_mean: 9.83e-01\t\n",
      "GradInit: Iter 30, obj iters 30, eta 1.000e-01, constraint count 0 loss: 2.108e+25 (2.543e+25), init loss: 6.909e+00 (6.910e+00), update loss 2.108e+24 (2.543e+24), total gnorm: 1.067e+03 (1.259e+03)\ts_max: 1.03e+00\ts_min: 9.70e-01\ts_mean: 9.88e-01\ts_weight_max: 1.03e+00\ts_weight_min: 9.70e-01\ts_weight_mean: 9.75e-01\t\n",
      "GradInit: Iter 40, obj iters 40, eta 1.000e-01, constraint count 0 loss: 1.569e+25 (2.458e+25), init loss: 6.910e+00 (6.910e+00), update loss 1.569e+24 (2.458e+24), total gnorm: 9.297e+02 (1.188e+03)\ts_max: 1.04e+00\ts_min: 9.60e-01\ts_mean: 9.84e-01\ts_weight_max: 1.04e+00\ts_weight_min: 9.60e-01\ts_weight_mean: 9.67e-01\t\n",
      "GradInit: Iter 50, obj iters 50, eta 1.000e-01, constraint count 0 loss: 1.284e+25 (2.561e+25), init loss: 6.909e+00 (6.910e+00), update loss 1.284e+24 (2.561e+24), total gnorm: 8.305e+02 (1.122e+03)\ts_max: 1.05e+00\ts_min: 9.50e-01\ts_mean: 9.80e-01\ts_weight_max: 1.05e+00\ts_weight_min: 9.50e-01\ts_weight_mean: 9.59e-01\t\n",
      "GradInit: Iter 60, obj iters 60, eta 1.000e-01, constraint count 0 loss: 2.343e+25 (2.534e+25), init loss: 6.909e+00 (6.910e+00), update loss 2.343e+24 (2.534e+24), total gnorm: 7.149e+02 (1.062e+03)\ts_max: 1.06e+00\ts_min: 9.40e-01\ts_mean: 9.76e-01\ts_weight_max: 1.06e+00\ts_weight_min: 9.40e-01\ts_weight_mean: 9.51e-01\t\n",
      "GradInit: Iter 70, obj iters 70, eta 1.000e-01, constraint count 0 loss: 1.514e+25 (2.725e+25), init loss: 6.909e+00 (6.910e+00), update loss 1.514e+24 (2.725e+24), total gnorm: 6.211e+02 (1.006e+03)\ts_max: 1.07e+00\ts_min: 9.30e-01\ts_mean: 9.72e-01\ts_weight_max: 1.07e+00\ts_weight_min: 9.30e-01\ts_weight_mean: 9.43e-01\t\n",
      "GradInit: Iter 80, obj iters 80, eta 1.000e-01, constraint count 0 loss: 3.673e+25 (2.831e+25), init loss: 6.909e+00 (6.909e+00), update loss 3.673e+24 (2.831e+24), total gnorm: 5.477e+02 (9.539e+02)\ts_max: 1.08e+00\ts_min: 9.20e-01\ts_mean: 9.68e-01\ts_weight_max: 1.08e+00\ts_weight_min: 9.20e-01\ts_weight_mean: 9.35e-01\t\n",
      "GradInit: Iter 90, obj iters 90, eta 1.000e-01, constraint count 0 loss: 2.134e+25 (2.763e+25), init loss: 6.909e+00 (6.909e+00), update loss 2.134e+24 (2.763e+24), total gnorm: 4.940e+02 (9.055e+02)\ts_max: 1.09e+00\ts_min: 9.10e-01\ts_mean: 9.64e-01\ts_weight_max: 1.09e+00\ts_weight_min: 9.10e-01\ts_weight_mean: 9.27e-01\t\n",
      "GradInit: Iter 100, obj iters 100, eta 1.000e-01, constraint count 0 loss: 2.999e+25 (2.815e+25), init loss: 6.908e+00 (6.909e+00), update loss 2.999e+24 (2.815e+24), total gnorm: 4.273e+02 (8.598e+02)\ts_max: 1.10e+00\ts_min: 9.00e-01\ts_mean: 9.60e-01\ts_weight_max: 1.10e+00\ts_weight_min: 9.00e-01\ts_weight_mean: 9.19e-01\t\n",
      "GradInit: Iter 110, obj iters 110, eta 1.000e-01, constraint count 0 loss: 4.651e+25 (2.799e+25), init loss: 6.908e+00 (6.909e+00), update loss 4.651e+24 (2.799e+24), total gnorm: 3.820e+02 (8.179e+02)\ts_max: 1.10e+00\ts_min: 8.90e-01\ts_mean: 9.56e-01\ts_weight_max: 1.10e+00\ts_weight_min: 8.90e-01\ts_weight_mean: 9.11e-01\t\n",
      "GradInit: Iter 120, obj iters 120, eta 1.000e-01, constraint count 0 loss: 2.473e+25 (2.777e+25), init loss: 6.908e+00 (6.909e+00), update loss 2.473e+24 (2.777e+24), total gnorm: 3.284e+02 (7.787e+02)\ts_max: 1.11e+00\ts_min: 8.80e-01\ts_mean: 9.52e-01\ts_weight_max: 1.11e+00\ts_weight_min: 8.80e-01\ts_weight_mean: 9.03e-01\t\n",
      "GradInit: Iter 130, obj iters 130, eta 1.000e-01, constraint count 0 loss: 3.271e+25 (2.802e+25), init loss: 6.908e+00 (6.909e+00), update loss 3.271e+24 (2.802e+24), total gnorm: 2.860e+02 (7.422e+02)\ts_max: 1.12e+00\ts_min: 8.70e-01\ts_mean: 9.48e-01\ts_weight_max: 1.12e+00\ts_weight_min: 8.70e-01\ts_weight_mean: 8.95e-01\t\n",
      "GradInit: Iter 140, obj iters 140, eta 1.000e-01, constraint count 0 loss: 1.062e+26 (2.821e+25), init loss: 6.908e+00 (6.909e+00), update loss 1.062e+25 (2.821e+24), total gnorm: 2.481e+02 (7.081e+02)\ts_max: 1.13e+00\ts_min: 8.60e-01\ts_mean: 9.43e-01\ts_weight_max: 1.13e+00\ts_weight_min: 8.60e-01\ts_weight_mean: 8.87e-01\t\n",
      "GradInit: Iter 150, obj iters 150, eta 1.000e-01, constraint count 0 loss: 2.820e+25 (2.834e+25), init loss: 6.908e+00 (6.909e+00), update loss 2.820e+24 (2.834e+24), total gnorm: 2.133e+02 (6.761e+02)\ts_max: 1.14e+00\ts_min: 8.50e-01\ts_mean: 9.39e-01\ts_weight_max: 1.14e+00\ts_weight_min: 8.50e-01\ts_weight_mean: 8.79e-01\t\n",
      "GradInit: Iter 160, obj iters 160, eta 1.000e-01, constraint count 0 loss: 2.332e+25 (2.822e+25), init loss: 6.908e+00 (6.909e+00), update loss 2.332e+24 (2.822e+24), total gnorm: 1.883e+02 (6.462e+02)\ts_max: 1.15e+00\ts_min: 8.40e-01\ts_mean: 9.35e-01\ts_weight_max: 1.15e+00\ts_weight_min: 8.40e-01\ts_weight_mean: 8.70e-01\t\n",
      "GradInit: Iter 170, obj iters 170, eta 1.000e-01, constraint count 0 loss: 1.151e+25 (2.805e+25), init loss: 6.908e+00 (6.909e+00), update loss 1.151e+24 (2.805e+24), total gnorm: 1.581e+02 (6.183e+02)\ts_max: 1.16e+00\ts_min: 8.30e-01\ts_mean: 9.31e-01\ts_weight_max: 1.16e+00\ts_weight_min: 8.30e-01\ts_weight_mean: 8.62e-01\t\n",
      "GradInit: Iter 180, obj iters 180, eta 1.000e-01, constraint count 0 loss: 5.669e+25 (2.843e+25), init loss: 6.908e+00 (6.909e+00), update loss 5.669e+24 (2.843e+24), total gnorm: 1.350e+02 (5.921e+02)\ts_max: 1.17e+00\ts_min: 8.20e-01\ts_mean: 9.27e-01\ts_weight_max: 1.17e+00\ts_weight_min: 8.20e-01\ts_weight_mean: 8.54e-01\t\n",
      "GradInit: Iter 190, obj iters 190, eta 1.000e-01, constraint count 0 loss: 1.988e+25 (2.806e+25), init loss: 6.908e+00 (6.909e+00), update loss 1.988e+24 (2.806e+24), total gnorm: 1.209e+02 (5.677e+02)\ts_max: 1.18e+00\ts_min: 8.10e-01\ts_mean: 9.23e-01\ts_weight_max: 1.18e+00\ts_weight_min: 8.10e-01\ts_weight_mean: 8.46e-01\t\n",
      "GradInit: Iter 200, obj iters 200, eta 1.000e-01, constraint count 0 loss: 5.048e+25 (2.803e+25), init loss: 6.908e+00 (6.909e+00), update loss 5.048e+24 (2.803e+24), total gnorm: 1.034e+02 (5.449e+02)\ts_max: 1.19e+00\ts_min: 8.00e-01\ts_mean: 9.19e-01\ts_weight_max: 1.19e+00\ts_weight_min: 8.00e-01\ts_weight_mean: 8.38e-01\t\n",
      "Model architecture:\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "INFO: Training VGG16 on CIFAR100 with lr 3e-05, num_epochs=60, weight_decay=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 0, 6.908, 0.00, 0.0\n",
      "Plot: Val, 0, 6.908, 0.00, 0.0\n",
      "Plot: Train, 1, 4.671, 1.04, 38.4\n",
      "Plot: Val, 1, 4.667, 0.85, 38.4\n",
      "Plot: Train, 2, 4.676, 1.00, 77.2\n",
      "Plot: Val, 2, 4.630, 1.01, 77.2\n",
      "Plot: Train, 3, 4.598, 1.00, 116.1\n",
      "Plot: Val, 3, 4.617, 0.99, 116.1\n",
      "Plot: Train, 4, 4.595, 1.04, 154.7\n",
      "Plot: Val, 4, 4.628, 0.85, 154.7\n",
      "Plot: Train, 5, 4.464, 2.15, 193.4\n",
      "Plot: Val, 5, 4.378, 2.09, 193.4\n",
      "Plot: Train, 6, 4.155, 3.40, 231.9\n",
      "Plot: Val, 6, 4.275, 3.20, 231.9\n",
      "Plot: Train, 7, 4.225, 5.78, 270.5\n",
      "Plot: Val, 7, 4.063, 5.12, 270.5\n",
      "Plot: Train, 8, 3.791, 8.45, 309.1\n",
      "Plot: Val, 8, 3.926, 7.92, 309.1\n",
      "Plot: Train, 9, 3.723, 9.76, 347.8\n",
      "Plot: Val, 9, 3.884, 9.25, 347.8\n",
      "Plot: Train, 10, 3.699, 11.55, 386.2\n",
      "Plot: Val, 10, 3.681, 10.94, 386.2\n",
      "Plot: Train, 11, 3.702, 9.75, 423.2\n",
      "Plot: Val, 11, 3.733, 8.95, 423.2\n",
      "Plot: Train, 12, 3.258, 12.47, 459.7\n",
      "Plot: Val, 12, 3.803, 11.54, 459.7\n",
      "Plot: Train, 13, 3.441, 13.75, 496.3\n",
      "Plot: Val, 13, 3.583, 12.81, 496.3\n",
      "Plot: Train, 14, 3.366, 14.71, 533.0\n",
      "Plot: Val, 14, 3.535, 13.51, 533.0\n",
      "Plot: Train, 15, 3.668, 13.80, 569.9\n",
      "Plot: Val, 15, 3.785, 12.47, 569.9\n",
      "Plot: Train, 16, 3.233, 14.88, 607.1\n",
      "Plot: Val, 16, 3.562, 13.51, 607.1\n",
      "Plot: Train, 17, 3.849, 15.98, 644.7\n",
      "Plot: Val, 17, 3.434, 14.27, 644.7\n",
      "Plot: Train, 18, 3.302, 17.02, 683.0\n",
      "Plot: Val, 18, 3.395, 14.99, 683.0\n",
      "Plot: Train, 19, 3.206, 16.41, 721.6\n",
      "Plot: Val, 19, 3.532, 14.59, 721.6\n",
      "Plot: Train, 20, 3.271, 16.22, 760.5\n",
      "Plot: Val, 20, 3.599, 14.43, 760.5\n",
      "Plot: Train, 21, 3.534, 18.30, 799.6\n",
      "Plot: Val, 21, 3.587, 15.48, 799.6\n",
      "Plot: Train, 22, 3.134, 20.03, 838.4\n",
      "Plot: Val, 22, 3.496, 16.95, 838.4\n",
      "Plot: Train, 23, 2.962, 21.82, 877.3\n",
      "Plot: Val, 23, 3.284, 17.57, 877.3\n",
      "Plot: Train, 24, 3.168, 19.91, 915.5\n",
      "Plot: Val, 24, 3.385, 16.74, 915.5\n",
      "Plot: Train, 25, 2.984, 22.17, 952.5\n",
      "Plot: Val, 25, 3.579, 17.12, 952.5\n",
      "Plot: Train, 26, 3.017, 21.50, 989.1\n",
      "Plot: Val, 26, 3.459, 17.01, 989.1\n",
      "Plot: Train, 27, 2.973, 23.33, 1025.8\n",
      "Plot: Val, 27, 3.426, 17.79, 1025.8\n",
      "Plot: Train, 28, 2.724, 26.24, 1062.5\n",
      "Plot: Val, 28, 3.271, 19.20, 1062.5\n",
      "Plot: Train, 29, 2.777, 26.07, 1099.1\n",
      "Plot: Val, 29, 3.368, 18.99, 1099.1\n",
      "Plot: Train, 30, 2.622, 27.95, 1135.5\n",
      "Plot: Val, 30, 3.243, 19.28, 1135.5\n",
      "Plot: Train, 31, 2.809, 28.89, 1171.9\n",
      "Plot: Val, 31, 3.233, 19.90, 1171.9\n",
      "Plot: Train, 32, 2.597, 26.70, 1208.5\n",
      "Plot: Val, 32, 3.601, 18.26, 1208.5\n",
      "Plot: Train, 33, 2.611, 28.67, 1245.2\n",
      "Plot: Val, 33, 3.473, 19.01, 1245.2\n",
      "Plot: Train, 34, 2.571, 32.52, 1282.1\n",
      "Plot: Val, 34, 3.327, 21.00, 1282.1\n",
      "Plot: Train, 35, 2.439, 33.27, 1319.4\n",
      "Plot: Val, 35, 3.578, 20.27, 1319.4\n",
      "Plot: Train, 36, 2.192, 36.75, 1357.2\n",
      "Plot: Val, 36, 3.176, 21.31, 1357.2\n",
      "Plot: Train, 37, 2.493, 33.73, 1395.7\n",
      "Plot: Val, 37, 3.402, 19.74, 1395.7\n",
      "Plot: Train, 38, 1.990, 38.78, 1434.6\n",
      "Plot: Val, 38, 3.488, 20.88, 1434.6\n",
      "Plot: Train, 39, 2.898, 30.04, 1473.7\n",
      "Plot: Val, 39, 3.840, 17.75, 1473.7\n",
      "Plot: Train, 40, 1.979, 40.48, 1512.7\n",
      "Plot: Val, 40, 3.418, 20.46, 1512.7\n",
      "Plot: Train, 41, 1.926, 42.47, 1550.0\n",
      "Plot: Val, 41, 3.676, 20.58, 1550.0\n",
      "Plot: Train, 42, 1.667, 42.54, 1586.7\n",
      "Plot: Val, 42, 3.829, 20.01, 1586.7\n",
      "Plot: Train, 43, 2.305, 39.81, 1623.3\n",
      "Plot: Val, 43, 4.259, 19.33, 1623.3\n",
      "Plot: Train, 44, 1.933, 47.29, 1660.0\n",
      "Plot: Val, 44, 4.046, 20.89, 1660.0\n",
      "Plot: Train, 45, 1.647, 42.17, 1696.7\n",
      "Plot: Val, 45, 4.123, 19.31, 1696.7\n",
      "Plot: Train, 46, 1.919, 43.72, 1733.8\n",
      "Plot: Val, 46, 3.946, 19.56, 1733.8\n",
      "Plot: Train, 47, 1.583, 52.36, 1771.2\n",
      "Plot: Val, 47, 4.455, 20.69, 1771.2\n",
      "Plot: Train, 48, 1.574, 46.17, 1809.4\n",
      "Plot: Val, 48, 4.493, 18.53, 1809.4\n",
      "Plot: Train, 49, 1.512, 56.98, 1848.0\n",
      "Plot: Val, 49, 4.714, 20.41, 1848.0\n",
      "Plot: Train, 50, 1.428, 57.49, 1886.9\n",
      "Plot: Val, 50, 4.533, 20.43, 1886.9\n",
      "Plot: Train, 51, 1.196, 59.00, 1926.1\n",
      "Plot: Val, 51, 4.406, 20.43, 1926.1\n",
      "Plot: Train, 52, 1.321, 60.56, 1965.0\n",
      "Plot: Val, 52, 5.157, 20.15, 1965.0\n",
      "Plot: Train, 53, 1.312, 56.00, 2002.2\n",
      "Plot: Val, 53, 5.513, 18.87, 2002.2\n",
      "Plot: Train, 54, 1.427, 58.00, 2038.8\n",
      "Plot: Val, 54, 5.220, 19.56, 2038.8\n",
      "Plot: Train, 55, 1.044, 66.89, 2075.3\n",
      "Plot: Val, 55, 5.328, 19.79, 2075.3\n",
      "Plot: Train, 56, 1.253, 63.18, 2111.7\n",
      "Plot: Val, 56, 5.219, 19.11, 2111.7\n",
      "Plot: Train, 57, 0.908, 65.61, 2148.1\n",
      "Plot: Val, 57, 5.326, 19.27, 2148.1\n",
      "Plot: Train, 58, 0.864, 70.06, 2184.6\n",
      "Plot: Val, 58, 6.245, 19.91, 2184.6\n",
      "Plot: Train, 59, 0.758, 75.52, 2221.3\n",
      "Plot: Val, 59, 5.135, 19.75, 2221.3\n",
      "Plot: Train, 60, 0.808, 74.00, 2258.2\n",
      "Plot: Val, 60, 5.750, 19.80, 2258.2\n",
      "Plot: Test, 5.750, 19.80, 2258.2\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "GradInit Args: adam, Iters 200, lr 0.01\n",
      "GradInit: Iter 10, obj iters 10, eta 1.000e-01, constraint count 0 loss: 2.685e+25 (2.798e+25), init loss: 6.908e+00 (6.909e+00), update loss 2.685e+24 (2.798e+24), total gnorm: 4.512e+02 (8.819e+02)\ts_max: 1.08e+00\ts_min: 9.00e-01\ts_mean: 9.58e-01\ts_weight_max: 1.08e+00\ts_weight_min: 9.00e-01\ts_weight_mean: 9.15e-01\t\n",
      "GradInit: Iter 20, obj iters 20, eta 1.000e-01, constraint count 0 loss: 1.839e+25 (2.676e+25), init loss: 6.908e+00 (6.909e+00), update loss 1.839e+24 (2.676e+24), total gnorm: 1.092e+02 (5.551e+02)\ts_max: 1.17e+00\ts_min: 8.00e-01\ts_mean: 9.17e-01\ts_weight_max: 1.17e+00\ts_weight_min: 8.00e-01\ts_weight_mean: 8.34e-01\t\n",
      "GradInit: Iter 30, obj iters 30, eta 1.000e-01, constraint count 0 loss: 2.350e+25 (2.870e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.350e+24 (2.870e+24), total gnorm: 2.565e+01 (3.882e+02)\ts_max: 1.26e+00\ts_min: 7.00e-01\ts_mean: 8.77e-01\ts_weight_max: 1.26e+00\ts_weight_min: 7.00e-01\ts_weight_mean: 7.54e-01\t\n",
      "GradInit: Iter 40, obj iters 40, eta 1.000e-01, constraint count 0 loss: 1.631e+25 (2.751e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.631e+24 (2.751e+24), total gnorm: 6.703e+00 (2.943e+02)\ts_max: 1.34e+00\ts_min: 6.00e-01\ts_mean: 8.36e-01\ts_weight_max: 1.34e+00\ts_weight_min: 6.00e-01\ts_weight_mean: 6.73e-01\t\n",
      "GradInit: Iter 50, obj iters 50, eta 1.000e-01, constraint count 0 loss: 1.222e+25 (2.832e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.222e+24 (2.832e+24), total gnorm: 3.569e+00 (2.363e+02)\ts_max: 1.43e+00\ts_min: 5.00e-01\ts_mean: 7.96e-01\ts_weight_max: 1.43e+00\ts_weight_min: 5.00e-01\ts_weight_mean: 5.93e-01\t\n",
      "GradInit: Iter 60, obj iters 60, eta 1.000e-01, constraint count 0 loss: 2.296e+25 (2.764e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.296e+24 (2.764e+24), total gnorm: 2.926e+00 (1.975e+02)\ts_max: 1.50e+00\ts_min: 4.00e-01\ts_mean: 7.56e-01\ts_weight_max: 1.50e+00\ts_weight_min: 4.00e-01\ts_weight_mean: 5.11e-01\t\n",
      "GradInit: Iter 70, obj iters 70, eta 1.000e-01, constraint count 0 loss: 1.383e+25 (2.905e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.383e+24 (2.905e+24), total gnorm: 2.687e+00 (1.696e+02)\ts_max: 1.58e+00\ts_min: 3.00e-01\ts_mean: 7.15e-01\ts_weight_max: 1.58e+00\ts_weight_min: 3.00e-01\ts_weight_mean: 4.30e-01\t\n",
      "GradInit: Iter 80, obj iters 80, eta 1.000e-01, constraint count 0 loss: 3.214e+25 (2.962e+25), init loss: 6.908e+00 (6.908e+00), update loss 3.214e+24 (2.962e+24), total gnorm: 2.452e+00 (1.488e+02)\ts_max: 1.67e+00\ts_min: 2.00e-01\ts_mean: 6.76e-01\ts_weight_max: 1.67e+00\ts_weight_min: 2.00e-01\ts_weight_mean: 3.51e-01\t\n",
      "GradInit: Iter 90, obj iters 90, eta 1.000e-01, constraint count 0 loss: 1.846e+25 (2.848e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.846e+24 (2.848e+24), total gnorm: 2.220e+00 (1.325e+02)\ts_max: 1.74e+00\ts_min: 1.00e-01\ts_mean: 6.36e-01\ts_weight_max: 1.74e+00\ts_weight_min: 1.00e-01\ts_weight_mean: 2.72e-01\t\n",
      "GradInit: Iter 100, obj iters 100, eta 1.000e-01, constraint count 0 loss: 2.565e+25 (2.857e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.565e+24 (2.857e+24), total gnorm: 2.022e+00 (1.195e+02)\ts_max: 1.82e+00\ts_min: 1.00e-02\ts_mean: 6.01e-01\ts_weight_max: 1.82e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.01e-01\t\n",
      "GradInit: Iter 110, obj iters 110, eta 1.000e-01, constraint count 0 loss: 4.122e+25 (2.798e+25), init loss: 6.908e+00 (6.908e+00), update loss 4.122e+24 (2.798e+24), total gnorm: 1.842e+00 (1.088e+02)\ts_max: 1.88e+00\ts_min: 1.00e-02\ts_mean: 5.98e-01\ts_weight_max: 1.88e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 1.97e-01\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradInit: Iter 120, obj iters 120, eta 1.000e-01, constraint count 0 loss: 1.953e+25 (2.740e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.953e+24 (2.740e+24), total gnorm: 1.824e+00 (9.986e+01)\ts_max: 1.93e+00\ts_min: 1.00e-02\ts_mean: 5.98e-01\ts_weight_max: 1.93e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 1.96e-01\t\n",
      "GradInit: Iter 130, obj iters 130, eta 1.000e-01, constraint count 0 loss: 2.600e+25 (2.727e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.600e+24 (2.727e+24), total gnorm: 1.824e+00 (9.232e+01)\ts_max: 1.99e+00\ts_min: 1.00e-02\ts_mean: 6.00e-01\ts_weight_max: 1.99e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.01e-01\t\n",
      "GradInit: Iter 140, obj iters 140, eta 1.000e-01, constraint count 0 loss: 8.974e+25 (2.717e+25), init loss: 6.908e+00 (6.908e+00), update loss 8.974e+24 (2.717e+24), total gnorm: 1.824e+00 (8.585e+01)\ts_max: 2.07e+00\ts_min: 1.00e-02\ts_mean: 6.02e-01\ts_weight_max: 2.07e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.05e-01\t\n",
      "GradInit: Iter 150, obj iters 150, eta 1.000e-01, constraint count 0 loss: 2.243e+25 (2.697e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.243e+24 (2.697e+24), total gnorm: 1.824e+00 (8.025e+01)\ts_max: 2.12e+00\ts_min: 1.00e-02\ts_mean: 6.04e-01\ts_weight_max: 2.12e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.08e-01\t\n",
      "GradInit: Iter 160, obj iters 160, eta 1.000e-01, constraint count 0 loss: 1.827e+25 (2.662e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.827e+24 (2.662e+24), total gnorm: 1.825e+00 (7.535e+01)\ts_max: 2.16e+00\ts_min: 1.00e-02\ts_mean: 6.07e-01\ts_weight_max: 2.16e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.13e-01\t\n",
      "GradInit: Iter 170, obj iters 170, eta 1.000e-01, constraint count 0 loss: 9.152e+24 (2.627e+25), init loss: 6.908e+00 (6.908e+00), update loss 9.152e+23 (2.627e+24), total gnorm: 1.824e+00 (7.102e+01)\ts_max: 2.21e+00\ts_min: 1.00e-02\ts_mean: 6.09e-01\ts_weight_max: 2.21e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.19e-01\t\n",
      "GradInit: Iter 180, obj iters 180, eta 1.000e-01, constraint count 0 loss: 4.707e+25 (2.638e+25), init loss: 6.908e+00 (6.908e+00), update loss 4.707e+24 (2.638e+24), total gnorm: 1.825e+00 (6.718e+01)\ts_max: 2.25e+00\ts_min: 1.00e-02\ts_mean: 6.11e-01\ts_weight_max: 2.25e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.22e-01\t\n",
      "GradInit: Iter 190, obj iters 190, eta 1.000e-01, constraint count 0 loss: 1.649e+25 (2.592e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.649e+24 (2.592e+24), total gnorm: 1.825e+00 (6.374e+01)\ts_max: 2.29e+00\ts_min: 1.00e-02\ts_mean: 6.12e-01\ts_weight_max: 2.29e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.24e-01\t\n",
      "GradInit: Iter 200, obj iters 200, eta 1.000e-01, constraint count 0 loss: 4.014e+25 (2.575e+25), init loss: 6.908e+00 (6.908e+00), update loss 4.014e+24 (2.575e+24), total gnorm: 1.825e+00 (6.064e+01)\ts_max: 2.34e+00\ts_min: 1.00e-02\ts_mean: 6.15e-01\ts_weight_max: 2.34e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.29e-01\t\n",
      "Model architecture:\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "INFO: Training VGG16 on CIFAR100 with lr 3e-05, num_epochs=60, weight_decay=0\n",
      "Plot: Train, 0, 6.908, 0.00, 0.0\n",
      "Plot: Val, 0, 6.908, 0.00, 0.0\n",
      "Plot: Train, 1, 4.668, 1.03, 36.4\n",
      "Plot: Val, 1, 4.628, 0.86, 36.4\n",
      "Plot: Train, 2, 4.617, 1.01, 73.0\n",
      "Plot: Val, 2, 4.607, 0.95, 73.0\n",
      "Plot: Train, 3, 4.597, 1.04, 109.7\n",
      "Plot: Val, 3, 4.607, 0.84, 109.7\n",
      "Plot: Train, 4, 4.604, 1.01, 146.3\n",
      "Plot: Val, 4, 4.623, 0.95, 146.3\n",
      "Plot: Train, 5, 4.610, 1.03, 182.8\n",
      "Plot: Val, 5, 4.617, 0.89, 182.8\n",
      "Plot: Train, 6, 4.599, 1.04, 219.1\n",
      "Plot: Val, 6, 4.610, 0.83, 219.1\n",
      "Plot: Train, 7, 4.611, 1.03, 255.4\n",
      "Plot: Val, 7, 4.615, 0.89, 255.4\n",
      "Plot: Train, 8, 4.608, 0.99, 292.0\n",
      "Plot: Val, 8, 4.610, 1.04, 292.0\n",
      "Plot: Train, 9, 4.606, 0.98, 328.5\n",
      "Plot: Val, 9, 4.607, 1.09, 328.5\n",
      "Plot: Train, 10, 4.614, 0.99, 365.0\n",
      "Plot: Val, 10, 4.611, 1.04, 365.0\n",
      "Plot: Train, 11, 4.606, 1.03, 401.5\n",
      "Plot: Val, 11, 4.616, 0.87, 401.5\n",
      "Plot: Train, 12, 4.580, 1.03, 438.1\n",
      "Plot: Val, 12, 4.615, 0.87, 438.1\n",
      "Plot: Train, 13, 4.606, 1.03, 474.6\n",
      "Plot: Val, 13, 4.607, 0.87, 474.6\n",
      "Plot: Train, 14, 4.613, 1.03, 511.3\n",
      "Plot: Val, 14, 4.613, 0.89, 511.3\n",
      "Plot: Train, 15, 4.610, 1.03, 547.7\n",
      "Plot: Val, 15, 4.611, 0.89, 547.7\n",
      "Plot: Train, 16, 4.610, 1.03, 583.9\n",
      "Plot: Val, 16, 4.610, 0.90, 583.9\n",
      "Plot: Train, 17, 4.608, 1.01, 620.2\n",
      "Plot: Val, 17, 4.605, 0.95, 620.2\n",
      "Plot: Train, 18, 4.598, 1.03, 656.3\n",
      "Plot: Val, 18, 4.613, 0.87, 656.3\n",
      "Plot: Train, 19, 4.606, 1.03, 691.1\n",
      "Plot: Val, 19, 4.612, 0.88, 691.1\n",
      "Plot: Train, 20, 4.604, 1.04, 725.5\n",
      "Plot: Val, 20, 4.618, 0.83, 725.5\n",
      "Plot: Train, 21, 4.621, 1.04, 759.8\n",
      "Plot: Val, 21, 4.612, 0.83, 759.8\n",
      "Plot: Train, 22, 4.616, 0.99, 794.2\n",
      "Plot: Val, 22, 4.606, 1.03, 794.2\n",
      "Plot: Train, 23, 4.609, 1.03, 828.8\n",
      "Plot: Val, 23, 4.611, 0.87, 828.8\n",
      "Plot: Train, 24, 4.621, 1.06, 863.5\n",
      "Plot: Val, 24, 4.615, 0.77, 863.5\n",
      "Plot: Train, 25, 4.605, 1.03, 898.5\n",
      "Plot: Val, 25, 4.613, 0.87, 898.5\n",
      "Plot: Train, 26, 4.607, 1.03, 934.1\n",
      "Plot: Val, 26, 4.608, 0.87, 934.1\n",
      "Plot: Train, 27, 4.606, 0.98, 970.1\n",
      "Plot: Val, 27, 4.607, 1.09, 970.1\n",
      "Plot: Train, 28, 4.610, 1.03, 1006.4\n",
      "Plot: Val, 28, 4.612, 0.86, 1006.4\n",
      "Plot: Train, 29, 4.610, 1.03, 1042.9\n",
      "Plot: Val, 29, 4.607, 0.86, 1042.9\n",
      "Plot: Train, 30, 4.608, 1.06, 1079.5\n",
      "Plot: Val, 30, 4.607, 0.77, 1079.5\n",
      "Plot: Train, 31, 4.613, 1.04, 1116.1\n",
      "Plot: Val, 31, 4.610, 0.85, 1116.1\n",
      "Plot: Train, 32, 4.606, 1.01, 1152.5\n",
      "Plot: Val, 32, 4.609, 0.95, 1152.5\n",
      "Plot: Train, 33, 4.607, 1.04, 1188.2\n",
      "Plot: Val, 33, 4.606, 0.84, 1188.2\n",
      "Plot: Train, 34, 4.606, 1.03, 1222.7\n",
      "Plot: Val, 34, 4.609, 0.90, 1222.7\n",
      "Plot: Train, 35, 4.604, 1.03, 1257.1\n",
      "Plot: Val, 35, 4.607, 0.88, 1257.1\n",
      "Plot: Train, 36, 4.602, 0.98, 1291.3\n",
      "Plot: Val, 36, 4.605, 1.07, 1291.3\n",
      "Plot: Train, 37, 4.601, 1.03, 1325.6\n",
      "Plot: Val, 37, 4.610, 0.87, 1325.6\n",
      "Plot: Train, 38, 4.610, 1.04, 1359.9\n",
      "Plot: Val, 38, 4.613, 0.85, 1359.9\n",
      "Plot: Train, 39, 4.605, 1.06, 1394.4\n",
      "Plot: Val, 39, 4.610, 0.77, 1394.4\n",
      "Plot: Train, 40, 4.599, 1.02, 1429.4\n",
      "Plot: Val, 40, 4.608, 0.91, 1429.4\n",
      "Plot: Train, 41, 4.606, 1.03, 1464.7\n",
      "Plot: Val, 41, 4.608, 0.88, 1464.7\n",
      "Plot: Train, 42, 4.610, 1.04, 1500.3\n",
      "Plot: Val, 42, 4.611, 0.85, 1500.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 43, 4.607, 1.03, 1536.5\n",
      "Plot: Val, 43, 4.608, 0.88, 1536.5\n",
      "Plot: Train, 44, 4.527, 1.03, 1572.1\n",
      "Plot: Val, 44, 4.572, 0.87, 1572.1\n",
      "Plot: Train, 45, 4.584, 1.03, 1607.1\n",
      "Plot: Val, 45, 4.550, 0.87, 1607.1\n",
      "Plot: Train, 46, 4.541, 1.15, 1642.1\n",
      "Plot: Val, 46, 4.586, 1.10, 1642.1\n",
      "Plot: Train, 47, 4.582, 1.03, 1677.0\n",
      "Plot: Val, 47, 4.550, 0.87, 1677.0\n",
      "Plot: Train, 48, 4.491, 1.93, 1712.1\n",
      "Plot: Val, 48, 4.492, 1.52, 1712.1\n",
      "Plot: Train, 49, 4.324, 2.00, 1747.4\n",
      "Plot: Val, 49, 4.456, 1.77, 1747.4\n",
      "Plot: Train, 50, 4.408, 2.10, 1782.9\n",
      "Plot: Val, 50, 4.348, 2.09, 1782.9\n",
      "Plot: Train, 51, 4.412, 2.74, 1818.9\n",
      "Plot: Val, 51, 4.381, 2.58, 1818.9\n",
      "Plot: Train, 52, 4.378, 2.42, 1855.4\n",
      "Plot: Val, 52, 4.416, 2.47, 1855.4\n",
      "Plot: Train, 53, 4.429, 2.80, 1892.1\n",
      "Plot: Val, 53, 4.369, 2.47, 1892.1\n",
      "Plot: Train, 54, 4.147, 3.14, 1929.2\n",
      "Plot: Val, 54, 4.312, 2.75, 1929.2\n",
      "Plot: Train, 55, 4.322, 3.45, 1966.3\n",
      "Plot: Val, 55, 4.313, 3.15, 1966.3\n",
      "Plot: Train, 56, 4.489, 3.28, 2003.3\n",
      "Plot: Val, 56, 4.209, 3.00, 2003.3\n",
      "Plot: Train, 57, 4.248, 3.68, 2040.2\n",
      "Plot: Val, 57, 4.340, 3.38, 2040.2\n",
      "Plot: Train, 58, 4.282, 4.05, 2076.4\n",
      "Plot: Val, 58, 4.324, 3.87, 2076.4\n",
      "Plot: Train, 59, 4.165, 3.94, 2111.6\n",
      "Plot: Val, 59, 4.138, 3.66, 2111.6\n",
      "Plot: Train, 60, 4.117, 4.27, 2146.6\n",
      "Plot: Val, 60, 4.277, 4.33, 2146.6\n",
      "Plot: Test, 4.277, 4.33, 2146.6\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "GradInit Args: adam, Iters 200, lr 0.1\n",
      "GradInit: Iter 10, obj iters 10, eta 1.000e-01, constraint count 0 loss: 2.195e+25 (2.775e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.195e+24 (2.775e+24), total gnorm: 2.036e+00 (1.956e+02)\ts_max: 1.82e+00\ts_min: 1.00e-02\ts_mean: 5.91e-01\ts_weight_max: 1.82e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 1.82e-01\t\n",
      "GradInit: Iter 20, obj iters 20, eta 1.000e-01, constraint count 0 loss: 1.414e+25 (2.441e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.414e+24 (2.441e+24), total gnorm: 1.823e+00 (9.871e+01)\ts_max: 2.56e+00\ts_min: 1.00e-02\ts_mean: 6.14e-01\ts_weight_max: 2.56e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.27e-01\t\n",
      "GradInit: Iter 30, obj iters 30, eta 1.000e-01, constraint count 0 loss: 1.923e+25 (2.534e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.923e+24 (2.534e+24), total gnorm: 1.824e+00 (6.641e+01)\ts_max: 2.72e+00\ts_min: 1.00e-02\ts_mean: 6.21e-01\ts_weight_max: 2.72e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.43e-01\t\n",
      "GradInit: Iter 40, obj iters 40, eta 1.000e-01, constraint count 0 loss: 1.331e+25 (2.403e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.331e+24 (2.403e+24), total gnorm: 1.824e+00 (5.026e+01)\ts_max: 2.67e+00\ts_min: 1.00e-02\ts_mean: 6.21e-01\ts_weight_max: 2.67e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.42e-01\t\n",
      "GradInit: Iter 50, obj iters 50, eta 1.000e-01, constraint count 0 loss: 9.554e+24 (2.481e+25), init loss: 6.908e+00 (6.908e+00), update loss 9.554e+23 (2.481e+24), total gnorm: 1.826e+00 (4.058e+01)\ts_max: 2.64e+00\ts_min: 1.00e-02\ts_mean: 6.28e-01\ts_weight_max: 2.64e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.56e-01\t\n",
      "GradInit: Iter 60, obj iters 60, eta 1.000e-01, constraint count 0 loss: 2.091e+25 (2.433e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.091e+24 (2.433e+24), total gnorm: 1.827e+00 (3.412e+01)\ts_max: 2.43e+00\ts_min: 1.00e-02\ts_mean: 6.26e-01\ts_weight_max: 2.43e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.53e-01\t\n",
      "GradInit: Iter 70, obj iters 70, eta 1.000e-01, constraint count 0 loss: 1.286e+25 (2.572e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.286e+24 (2.572e+24), total gnorm: 1.827e+00 (2.951e+01)\ts_max: 2.09e+00\ts_min: 1.00e-02\ts_mean: 6.14e-01\ts_weight_max: 2.09e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.28e-01\t\n",
      "GradInit: Iter 80, obj iters 80, eta 1.000e-01, constraint count 0 loss: 3.001e+25 (2.643e+25), init loss: 6.908e+00 (6.908e+00), update loss 3.001e+24 (2.643e+24), total gnorm: 1.829e+00 (2.605e+01)\ts_max: 2.10e+00\ts_min: 1.00e-02\ts_mean: 6.25e-01\ts_weight_max: 2.10e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.50e-01\t\n",
      "GradInit: Iter 90, obj iters 90, eta 1.000e-01, constraint count 0 loss: 1.763e+25 (2.554e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.763e+24 (2.554e+24), total gnorm: 1.830e+00 (2.335e+01)\ts_max: 2.37e+00\ts_min: 1.00e-02\ts_mean: 6.39e-01\ts_weight_max: 2.37e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.78e-01\t\n",
      "GradInit: Iter 100, obj iters 100, eta 1.000e-01, constraint count 0 loss: 2.603e+25 (2.587e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.603e+24 (2.587e+24), total gnorm: 1.832e+00 (2.120e+01)\ts_max: 2.43e+00\ts_min: 1.00e-02\ts_mean: 6.49e-01\ts_weight_max: 2.43e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 2.97e-01\t\n",
      "GradInit: Iter 110, obj iters 110, eta 1.000e-01, constraint count 0 loss: 4.128e+25 (2.552e+25), init loss: 6.908e+00 (6.908e+00), update loss 4.128e+24 (2.552e+24), total gnorm: 1.836e+00 (1.944e+01)\ts_max: 2.52e+00\ts_min: 1.00e-02\ts_mean: 6.55e-01\ts_weight_max: 2.52e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 3.09e-01\t\n",
      "GradInit: Iter 120, obj iters 120, eta 1.000e-01, constraint count 0 loss: 1.885e+25 (2.512e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.885e+24 (2.512e+24), total gnorm: 1.837e+00 (1.797e+01)\ts_max: 2.74e+00\ts_min: 1.00e-02\ts_mean: 6.68e-01\ts_weight_max: 2.74e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 3.35e-01\t\n",
      "GradInit: Iter 130, obj iters 130, eta 1.000e-01, constraint count 0 loss: 2.588e+25 (2.517e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.588e+24 (2.517e+24), total gnorm: 1.839e+00 (1.673e+01)\ts_max: 3.04e+00\ts_min: 1.00e-02\ts_mean: 6.87e-01\ts_weight_max: 3.04e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 3.74e-01\t\n",
      "GradInit: Iter 140, obj iters 140, eta 1.000e-01, constraint count 0 loss: 9.456e+25 (2.525e+25), init loss: 6.908e+00 (6.908e+00), update loss 9.456e+24 (2.525e+24), total gnorm: 1.838e+00 (1.567e+01)\ts_max: 2.93e+00\ts_min: 1.00e-02\ts_mean: 6.86e-01\ts_weight_max: 2.93e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 3.72e-01\t\n",
      "GradInit: Iter 150, obj iters 150, eta 1.000e-01, constraint count 0 loss: 2.211e+25 (2.518e+25), init loss: 6.908e+00 (6.908e+00), update loss 2.211e+24 (2.518e+24), total gnorm: 1.838e+00 (1.475e+01)\ts_max: 3.02e+00\ts_min: 1.00e-02\ts_mean: 6.84e-01\ts_weight_max: 3.02e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 3.68e-01\t\n",
      "GradInit: Iter 160, obj iters 160, eta 1.000e-01, constraint count 0 loss: 1.810e+25 (2.493e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.810e+24 (2.493e+24), total gnorm: 1.842e+00 (1.394e+01)\ts_max: 3.44e+00\ts_min: 1.00e-02\ts_mean: 6.93e-01\ts_weight_max: 3.44e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 3.87e-01\t\n",
      "GradInit: Iter 170, obj iters 170, eta 1.000e-01, constraint count 0 loss: 9.141e+24 (2.469e+25), init loss: 6.908e+00 (6.908e+00), update loss 9.141e+23 (2.469e+24), total gnorm: 1.844e+00 (1.323e+01)\ts_max: 3.92e+00\ts_min: 1.00e-02\ts_mean: 7.04e-01\ts_weight_max: 3.92e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 4.07e-01\t\n",
      "GradInit: Iter 180, obj iters 180, eta 1.000e-01, constraint count 0 loss: 4.786e+25 (2.489e+25), init loss: 6.908e+00 (6.908e+00), update loss 4.786e+24 (2.489e+24), total gnorm: 1.845e+00 (1.260e+01)\ts_max: 3.97e+00\ts_min: 1.00e-02\ts_mean: 7.03e-01\ts_weight_max: 3.97e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 4.05e-01\t\n",
      "GradInit: Iter 190, obj iters 190, eta 1.000e-01, constraint count 0 loss: 1.617e+25 (2.451e+25), init loss: 6.908e+00 (6.908e+00), update loss 1.617e+24 (2.451e+24), total gnorm: 1.845e+00 (1.203e+01)\ts_max: 3.94e+00\ts_min: 1.00e-02\ts_mean: 7.05e-01\ts_weight_max: 3.94e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 4.11e-01\t\n",
      "GradInit: Iter 200, obj iters 200, eta 1.000e-01, constraint count 0 loss: 4.034e+25 (2.442e+25), init loss: 6.908e+00 (6.908e+00), update loss 4.034e+24 (2.442e+24), total gnorm: 1.847e+00 (1.152e+01)\ts_max: 4.17e+00\ts_min: 1.00e-02\ts_mean: 7.23e-01\ts_weight_max: 4.17e+00\ts_weight_min: 1.00e-02\ts_weight_mean: 4.46e-01\t\n",
      "Model architecture:\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "INFO: Training VGG16 on CIFAR100 with lr 3e-05, num_epochs=60, weight_decay=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 0, 6.908, 0.00, 0.0\n",
      "Plot: Val, 0, 6.908, 0.00, 0.0\n",
      "Plot: Train, 1, 4.629, 1.03, 34.8\n",
      "Plot: Val, 1, 4.624, 0.88, 34.8\n",
      "Plot: Train, 2, 4.617, 1.01, 69.6\n",
      "Plot: Val, 2, 4.607, 0.95, 69.6\n",
      "Plot: Train, 3, 4.597, 1.04, 104.6\n",
      "Plot: Val, 3, 4.607, 0.84, 104.6\n",
      "Plot: Train, 4, 4.605, 1.01, 139.9\n",
      "Plot: Val, 4, 4.623, 0.95, 139.9\n",
      "Plot: Train, 5, 4.610, 1.03, 175.8\n",
      "Plot: Val, 5, 4.617, 0.89, 175.8\n",
      "Plot: Train, 6, 4.600, 1.04, 212.1\n",
      "Plot: Val, 6, 4.610, 0.83, 212.1\n",
      "Plot: Train, 7, 4.611, 1.03, 247.4\n",
      "Plot: Val, 7, 4.615, 0.87, 247.4\n",
      "Plot: Train, 8, 4.608, 0.99, 282.2\n",
      "Plot: Val, 8, 4.611, 1.04, 282.2\n",
      "Plot: Train, 9, 4.607, 1.00, 317.1\n",
      "Plot: Val, 9, 4.607, 0.98, 317.1\n",
      "Plot: Train, 10, 4.613, 0.99, 351.9\n",
      "Plot: Val, 10, 4.611, 1.04, 351.9\n",
      "Plot: Train, 11, 4.606, 1.03, 387.0\n",
      "Plot: Val, 11, 4.616, 0.87, 387.0\n",
      "Plot: Train, 12, 4.580, 1.03, 422.2\n",
      "Plot: Val, 12, 4.614, 0.87, 422.2\n",
      "Plot: Train, 13, 4.604, 1.01, 457.6\n",
      "Plot: Val, 13, 4.607, 0.95, 457.6\n",
      "Plot: Train, 14, 4.613, 1.03, 493.5\n",
      "Plot: Val, 14, 4.613, 0.89, 493.5\n",
      "Plot: Train, 15, 4.607, 1.03, 530.0\n",
      "Plot: Val, 15, 4.610, 0.89, 530.0\n",
      "Plot: Train, 16, 4.487, 1.00, 566.7\n",
      "Plot: Val, 16, 4.504, 1.02, 566.7\n",
      "Plot: Train, 17, 4.467, 1.04, 603.8\n",
      "Plot: Val, 17, 4.548, 0.83, 603.8\n",
      "Plot: Train, 18, 4.578, 1.01, 641.0\n",
      "Plot: Val, 18, 4.538, 0.97, 641.0\n",
      "Plot: Train, 19, 4.531, 1.01, 678.2\n",
      "Plot: Val, 19, 4.542, 0.97, 678.2\n",
      "Plot: Train, 20, 4.443, 0.98, 715.4\n",
      "Plot: Val, 20, 4.540, 1.09, 715.4\n",
      "Plot: Train, 21, 4.528, 1.04, 752.7\n",
      "Plot: Val, 21, 4.556, 0.83, 752.7\n",
      "Plot: Train, 22, 4.441, 1.01, 789.9\n",
      "Plot: Val, 22, 4.515, 0.97, 789.9\n",
      "Plot: Train, 23, 4.531, 1.00, 827.1\n",
      "Plot: Val, 23, 4.487, 1.02, 827.1\n",
      "Plot: Train, 24, 4.535, 0.99, 864.3\n",
      "Plot: Val, 24, 4.519, 1.04, 864.3\n",
      "Plot: Train, 25, 4.509, 0.98, 901.3\n",
      "Plot: Val, 25, 4.445, 1.09, 901.3\n",
      "Plot: Train, 26, 4.358, 1.00, 938.2\n",
      "Plot: Val, 26, 4.500, 1.02, 938.2\n",
      "Plot: Train, 27, 4.492, 1.01, 975.2\n",
      "Plot: Val, 27, 4.491, 0.97, 975.2\n",
      "Plot: Train, 28, 4.443, 1.05, 1012.5\n",
      "Plot: Val, 28, 4.427, 1.02, 1012.5\n",
      "Plot: Train, 29, 4.450, 2.18, 1049.6\n",
      "Plot: Val, 29, 4.466, 1.90, 1049.6\n",
      "Plot: Train, 30, 4.291, 2.58, 1086.9\n",
      "Plot: Val, 30, 4.258, 2.54, 1086.9\n",
      "Plot: Train, 31, 4.243, 3.16, 1124.2\n",
      "Plot: Val, 31, 4.114, 2.88, 1124.2\n",
      "Plot: Train, 32, 4.372, 3.28, 1161.5\n",
      "Plot: Val, 32, 4.254, 3.41, 1161.5\n",
      "Plot: Train, 33, 4.214, 2.94, 1198.9\n",
      "Plot: Val, 33, 4.247, 2.59, 1198.9\n",
      "Plot: Train, 34, 4.171, 3.37, 1236.2\n",
      "Plot: Val, 34, 4.310, 3.44, 1236.2\n",
      "Plot: Train, 35, 4.286, 3.21, 1273.5\n",
      "Plot: Val, 35, 4.248, 3.04, 1273.5\n",
      "Plot: Train, 36, 4.036, 3.92, 1310.8\n",
      "Plot: Val, 36, 4.146, 3.91, 1310.8\n",
      "Plot: Train, 37, 4.430, 3.95, 1348.1\n",
      "Plot: Val, 37, 4.198, 3.71, 1348.1\n",
      "Plot: Train, 38, 4.179, 4.32, 1385.3\n",
      "Plot: Val, 38, 4.116, 3.70, 1385.3\n",
      "Plot: Train, 39, 4.252, 4.45, 1422.5\n",
      "Plot: Val, 39, 4.133, 4.08, 1422.5\n",
      "Plot: Train, 40, 4.028, 4.45, 1459.7\n",
      "Plot: Val, 40, 4.089, 4.31, 1459.7\n",
      "Plot: Train, 41, 4.157, 4.78, 1496.9\n",
      "Plot: Val, 41, 4.208, 4.70, 1496.9\n",
      "Plot: Train, 42, 4.053, 5.18, 1534.2\n",
      "Plot: Val, 42, 4.070, 4.92, 1534.2\n",
      "Plot: Train, 43, 4.192, 5.55, 1571.3\n",
      "Plot: Val, 43, 4.124, 5.50, 1571.3\n",
      "Plot: Train, 44, 3.996, 5.16, 1608.5\n",
      "Plot: Val, 44, 4.105, 4.40, 1608.5\n",
      "Plot: Train, 45, 3.988, 5.67, 1645.7\n",
      "Plot: Val, 45, 4.017, 5.67, 1645.7\n",
      "Plot: Train, 46, 4.142, 5.91, 1682.9\n",
      "Plot: Val, 46, 4.049, 5.56, 1682.9\n",
      "Plot: Train, 47, 3.912, 6.13, 1720.1\n",
      "Plot: Val, 47, 4.031, 5.95, 1720.1\n",
      "Plot: Train, 48, 3.839, 6.20, 1757.2\n",
      "Plot: Val, 48, 4.027, 6.17, 1757.2\n",
      "Plot: Train, 49, 4.111, 6.37, 1794.3\n",
      "Plot: Val, 49, 4.124, 5.89, 1794.3\n",
      "Plot: Train, 50, 3.997, 6.69, 1831.4\n",
      "Plot: Val, 50, 4.000, 6.45, 1831.4\n",
      "Plot: Train, 54, 3.802, 7.03, 1979.8\n",
      "Plot: Val, 54, 3.982, 6.63, 1979.8\n",
      "Plot: Train, 55, 3.969, 7.36, 2017.0\n",
      "Plot: Val, 55, 4.044, 7.01, 2017.0\n",
      "Plot: Train, 56, 4.152, 7.29, 2054.0\n",
      "Plot: Val, 56, 3.982, 6.96, 2054.0\n",
      "Plot: Train, 57, 3.812, 7.21, 2091.2\n",
      "Plot: Val, 57, 4.015, 6.82, 2091.2\n",
      "Plot: Train, 58, 3.957, 7.50, 2128.3\n",
      "Plot: Val, 58, 4.113, 6.97, 2128.3\n",
      "Plot: Train, 59, 4.003, 7.38, 2165.5\n",
      "Plot: Val, 59, 3.814, 6.90, 2165.5\n",
      "Plot: Train, 60, 3.891, 7.73, 2202.6\n",
      "Plot: Val, 60, 3.958, 7.32, 2202.6\n",
      "Plot: Test, 3.958, 7.32, 2202.6\n"
     ]
    }
   ],
   "source": [
    "gradinit_params = {\n",
    "    \"gradinit_iters\": 200,\n",
    "    \"gradinit_alg\": \"adam\", #sgd\n",
    "    \"gradinit_lr\": 1e-2,\n",
    "    \"gradinit_grad_clip\": 1,\n",
    "}\n",
    "model_params = {\n",
    "    \"gradinit\": gradinit_params,\n",
    "    # \"convnorm\" : True,\n",
    "    # \"approx_mult\" : 0.2,\n",
    "    # \"importance_sampling\" : True,\n",
    "    # \"gamma\" : 0.9\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-5,\n",
    "    \"num_epochs\" : 60,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 512,\n",
    "}\n",
    "\n",
    "\n",
    "def test_setup():\n",
    "  for lr in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    gradinit_params['gradinit_lr'] = lr\n",
    "    model_params = {\n",
    "        \"gradinit\": gradinit_params,\n",
    "    }\n",
    "    train_model('VGG16', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradinit_params = {\n",
    "#     \"gradinit_iters\": 200,\n",
    "#     \"gradinit_alg\": \"adam\", #sgd\n",
    "#     \"gradinit_lr\": 1e-5,\n",
    "#     \"gradinit_grad_clip\": 1,\n",
    "# }\n",
    "# model_params = {\n",
    "#     \"gradinit\": gradinit_params,\n",
    "#     # \"convnorm\" : True,\n",
    "#     # \"approx_mult\" : 0.2,\n",
    "#     # \"importance_sampling\" : True,\n",
    "#     # \"gamma\" : 0.9\n",
    "# }\n",
    "# hyperparams = {\n",
    "#     \"lr\" : 3e-5,\n",
    "#     \"num_epochs\" : 60,\n",
    "#     \"weight_decay\" : 0,\n",
    "#     \"train_ratio\" : 0.8,\n",
    "#     \"batch_size\" : 512,\n",
    "# }\n",
    "\n",
    "\n",
    "# def test_setup():\n",
    "#   for iters in [50, 100, 200, 350, 500]:\n",
    "#     gradinit_params['gradinit_iters'] = iters\n",
    "#     model_params = {\n",
    "#         \"gradinit\": gradinit_params,\n",
    "#     }\n",
    "#     train_model('VGG16', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "# test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_p37",
   "language": "python",
   "name": "pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
