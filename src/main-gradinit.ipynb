{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1653204886178,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "bFB6WDmimTpS",
    "outputId": "672d2a42-ea4c-43f3-e1ca-1367c2868357"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# FOLDERNAME = 'CS231n_project/'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4353,
     "status": "ok",
     "timestamp": 1653204890527,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "ejjKJYC2YffB",
    "outputId": "7a1aad97-7fc6-4c21-fa04-24f4508284e0"
   },
   "outputs": [],
   "source": [
    "# !pip install torch==1.7 torchvision==0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6003,
     "status": "ok",
     "timestamp": 1653204896527,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "TzJV-LLVhBt5",
    "outputId": "03468936-f099-4c8f-935b-9dfc257e456a"
   },
   "outputs": [],
   "source": [
    "# %cd approx/src/pytorch/cpp\n",
    "# !python setup.py install\n",
    "# %cd ../../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1653204897473,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "uGvmWqNZD2hh",
    "outputId": "fd0ce3ef-78c9-4a72-bef1-a3b94a03a0e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from conv_norm import PreConv\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from utils import ImportanceSampler\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653204897475,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "BMatykiuGnJT"
   },
   "outputs": [],
   "source": [
    "from utils import get_accuracy, load_dataset\n",
    "from models import get_model\n",
    "check_accuracy = lambda loader, model: get_accuracy(loader, model, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1653206021690,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "dLHtcW9UHqOt"
   },
   "outputs": [],
   "source": [
    "def train_model(model_name, dataset_name, model_params={}, hyperparams={}):\n",
    "\n",
    "  learning_rate = hyperparams.get('lr', 1e-3)\n",
    "  num_epochs = hyperparams.get('num_epochs', 10)\n",
    "  weight_decay = hyperparams.get('weight_decay', 0)\n",
    "  train_ratio = hyperparams.get('train_ratio', 0.8)\n",
    "  batch_size = hyperparams.get('batch_size', 64)\n",
    "  seed = hyperparams.get('seed', 0)\n",
    "  imp_sampling = model_params.get('importance_sampling', False)\n",
    "  gamma = model_params.get('gamma', 0.9)\n",
    "\n",
    "  torch.manual_seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  loader_train, loader_val, loader_test, num_train, num_channels = load_dataset(dataset_name, train_ratio, batch_size)\n",
    "  model = get_model(model_name, model_params, learning_rate, loader_train, num_channels, device)\n",
    "\n",
    "  print(\"Model architecture:\")\n",
    "  print(model)\n",
    "\n",
    "  print(f'INFO: Training {model_name} on {dataset_name} with lr {learning_rate}, num_epochs={num_epochs}, weight_decay={weight_decay}')\n",
    "\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "\n",
    "  epoch_vals = []\n",
    "  \n",
    "  weight = torch.tensor([1.0]*num_train)\n",
    "\n",
    "  t_acc, t_loss = check_accuracy(loader_train, model)\n",
    "  val_acc, val_loss = check_accuracy(loader_val, model)\n",
    "  \n",
    "  start = timer()\n",
    "  c_time = timer()-start\n",
    "\n",
    "  print(f'Plot: Train, {0}, {t_loss:.3f}, {t_acc:.2f}, {c_time:.1f}')\n",
    "  print(f'Plot: Val, {0}, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  for e in range(num_epochs):\n",
    "    model.train()\n",
    "    doUniform = (e == 0) or (imp_sampling == False)\n",
    "    loader_train_sampled = loader_train\n",
    "    if not doUniform:\n",
    "      train_sampler = ImportanceSampler(num_train, weight, batch_size)\n",
    "      loader_train_sampled, _, _, _, _ = load_dataset(dataset_name, train_ratio, batch_size, train_sampler)\n",
    "    \n",
    "    for t, tpl in enumerate(loader_train_sampled):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()  # put model to training mode\n",
    "        x = tpl[0].to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "        y = tpl[1].to(device=device, dtype=torch.long)\n",
    "\n",
    "        scores = model(x)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not doUniform:\n",
    "          idx = tpl[2]\n",
    "          weight[idx] = gamma * weight[idx] + (1 - gamma) * float(loss)\n",
    "\n",
    "    t_acc, t_loss = check_accuracy(loader_train, model)\n",
    "    model.eval()\n",
    "    val_acc, val_loss = check_accuracy(loader_val, model)\n",
    "    c_time = timer()-start\n",
    "\n",
    "    print(f'Plot: Train, {e+1}, {t_loss:.3f}, {t_acc:.2f}, {c_time:.1f}')\n",
    "    print(f'Plot: Val, {e+1}, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  test_acc, test_loss = check_accuracy(loader_test, model)\n",
    "  print(f'Plot: Test, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhJmW7E1cMBF",
    "outputId": "d812c321-f54b-4aaf-c69b-ce76893369c6"
   },
   "outputs": [],
   "source": [
    "gradinit_params = {\n",
    "    \"gradinit_iters\": 200,\n",
    "    \"gradinit_alg\": \"adam\", #sgd\n",
    "    \"gradinit_lr\": 1e-2,\n",
    "    \"gradinit_grad_clip\": 1,\n",
    "}\n",
    "model_params = {\n",
    "    \"gradinit\": gradinit_params,\n",
    "    # \"convnorm\" : True,\n",
    "    # \"approx_mult\" : 0.2,\n",
    "    # \"importance_sampling\" : True,\n",
    "    # \"gamma\" : 0.9\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-3,\n",
    "    \"num_epochs\" : 25,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 1024,\n",
    "}\n",
    "\n",
    "def test_setup():\n",
    "  for lr in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    gradinit_params['gradinit_lr'] = lr\n",
    "    model_params = {\n",
    "        \"gradinit\": gradinit_params,\n",
    "    }\n",
    "    train_model('Resnet18', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradinit_params = {\n",
    "    \"gradinit_iters\": 200,\n",
    "    \"gradinit_alg\": \"adam\", #sgd\n",
    "    \"gradinit_lr\": 1e-4, \n",
    "    \"gradinit_grad_clip\": 1,\n",
    "}\n",
    "model_params = {\n",
    "    \"gradinit\": gradinit_params,\n",
    "    \"convnorm\" : {\"mode_conv\": [('first_frac', 0.25)], \"mode_bn\": [('first_frac', 0.25)]},\n",
    "    \"approx_mult\" : {'mult_val' : 0.8, 'mode_linear' : [('last_num', 1)], 'mode_conv' : [('last_num', 1)]},\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-3,\n",
    "    \"num_epochs\" : 25,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 512,\n",
    "}\n",
    "\n",
    "def test_setup():\n",
    "    train_model('Resnet18', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=25, weight_decay=0\n",
      "Plot: Train, 0, 6.908, 0.00, 0.0\n",
      "Plot: Val, 0, 6.924, 0.00, 0.0\n",
      "Plot: Train, 1, 3.974, 14.23, 40.8\n",
      "Plot: Val, 1, 3.988, 13.46, 40.8\n",
      "Plot: Train, 2, 3.147, 24.72, 82.2\n",
      "Plot: Val, 2, 3.223, 21.97, 82.2\n",
      "Plot: Train, 3, 2.841, 28.06, 122.9\n",
      "Plot: Val, 3, 3.147, 22.69, 122.9\n",
      "Plot: Train, 4, 2.508, 34.52, 163.4\n",
      "Plot: Val, 4, 2.856, 28.16, 163.4\n",
      "Plot: Train, 5, 2.118, 40.27, 204.5\n",
      "Plot: Val, 5, 2.714, 31.07, 204.5\n",
      "Plot: Train, 6, 2.372, 44.16, 246.0\n",
      "Plot: Val, 6, 2.857, 33.01, 246.0\n",
      "Plot: Train, 7, 1.819, 52.96, 287.5\n",
      "Plot: Val, 7, 2.506, 36.41, 287.5\n",
      "Plot: Train, 8, 1.323, 54.93, 328.8\n",
      "Plot: Val, 8, 2.746, 34.38, 328.8\n",
      "Plot: Train, 9, 1.137, 62.37, 369.3\n",
      "Plot: Val, 9, 2.623, 37.24, 369.3\n",
      "Plot: Train, 10, 1.345, 66.75, 410.2\n",
      "Plot: Val, 10, 2.797, 36.66, 410.2\n",
      "Plot: Train, 11, 0.982, 72.23, 451.4\n",
      "Plot: Val, 11, 2.838, 36.92, 451.4\n",
      "Plot: Train, 12, 0.893, 73.95, 492.0\n",
      "Plot: Val, 12, 3.207, 35.69, 492.0\n",
      "Plot: Train, 13, 0.546, 82.03, 532.8\n",
      "Plot: Val, 13, 3.140, 38.02, 532.8\n",
      "Plot: Train, 14, 0.437, 87.27, 574.0\n",
      "Plot: Val, 14, 3.176, 39.17, 574.0\n",
      "Plot: Train, 15, 0.349, 87.30, 614.3\n",
      "Plot: Val, 15, 3.261, 37.65, 614.3\n",
      "Plot: Train, 16, 0.211, 91.92, 655.1\n",
      "Plot: Val, 16, 3.682, 38.51, 655.1\n",
      "Plot: Train, 17, 0.189, 93.64, 696.3\n",
      "Plot: Val, 17, 3.776, 39.99, 696.3\n",
      "Plot: Train, 18, 0.177, 94.06, 736.8\n",
      "Plot: Val, 18, 3.862, 39.54, 736.8\n",
      "Plot: Train, 19, 0.155, 93.88, 777.1\n",
      "Plot: Val, 19, 3.942, 38.92, 777.1\n",
      "Plot: Train, 20, 0.210, 95.68, 817.9\n",
      "Plot: Val, 20, 3.780, 39.27, 817.9\n",
      "Plot: Train, 21, 0.056, 96.36, 859.3\n",
      "Plot: Val, 21, 3.981, 39.22, 859.3\n",
      "Plot: Train, 22, 0.113, 95.85, 900.6\n",
      "Plot: Val, 22, 4.038, 39.32, 900.6\n",
      "Plot: Train, 23, 0.083, 97.67, 941.6\n",
      "Plot: Val, 23, 3.892, 40.72, 941.6\n",
      "Plot: Train, 24, 0.087, 98.61, 982.5\n",
      "Plot: Val, 24, 4.166, 40.68, 982.5\n",
      "Plot: Train, 25, 0.035, 99.06, 1023.4\n",
      "Plot: Val, 25, 4.330, 41.48, 1023.4\n",
      "Plot: Test, 4.330, 41.48, 1023.4\n"
     ]
    }
   ],
   "source": [
    "gradinit_params = {\n",
    "    \"gradinit_iters\": 200,\n",
    "    \"gradinit_alg\": \"adam\", #sgd\n",
    "    \"gradinit_lr\": 1e-4, \n",
    "    \"gradinit_grad_clip\": 1,\n",
    "}\n",
    "model_params = {\n",
    "#     \"gradinit\": gradinit_params,\n",
    "#     \"convnorm\" : {\"mode_conv\": [('first_frac', 0.25)], \"mode_bn\": [('first_frac', 0.25)]},\n",
    "#     \"approx_mult\" : {'mult_val' : 0.8, 'mode_linear' : [('last_num', 1)], 'mode_conv' : [('last_num', 1)]},\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-3,\n",
    "    \"num_epochs\" : 25,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 1024,\n",
    "}\n",
    "\n",
    "def test_setup():\n",
    "    train_model('Resnet18', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 1\n",
      "Replace layers list is: [0]\n",
      "Number of og layers are 0, number of new layers are 1\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [19]\n",
      "Number of og layers are 19, number of new layers are 1\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): approx_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): approx_Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=25, weight_decay=0\n",
      "Plot: Train, 0, 6.941, 0.00, 0.0\n",
      "Plot: Val, 0, 6.940, 0.00, 0.0\n",
      "Plot: Train, 1, 3.935, 15.75, 41.1\n",
      "Plot: Val, 1, 3.733, 14.52, 41.1\n",
      "Plot: Train, 2, 2.875, 23.71, 82.7\n",
      "Plot: Val, 2, 3.178, 20.85, 82.7\n",
      "Plot: Train, 3, 3.237, 27.82, 124.0\n",
      "Plot: Val, 3, 3.162, 23.53, 124.0\n",
      "Plot: Train, 4, 2.414, 34.98, 165.3\n",
      "Plot: Val, 4, 2.964, 28.32, 165.3\n",
      "Plot: Train, 5, 2.412, 41.61, 206.5\n",
      "Plot: Val, 5, 2.806, 31.87, 206.5\n",
      "Plot: Train, 6, 1.937, 45.62, 247.6\n",
      "Plot: Val, 6, 2.678, 33.07, 247.6\n",
      "Plot: Train, 7, 1.902, 49.79, 288.6\n",
      "Plot: Val, 7, 2.716, 34.29, 288.6\n",
      "Plot: Train, 8, 1.773, 53.89, 329.5\n",
      "Plot: Val, 8, 2.693, 34.91, 329.5\n",
      "Plot: Train, 9, 1.281, 62.54, 370.5\n",
      "Plot: Val, 9, 2.642, 36.42, 370.5\n",
      "Plot: Train, 10, 1.206, 61.79, 411.4\n",
      "Plot: Val, 10, 2.895, 35.44, 411.4\n",
      "Plot: Train, 11, 1.135, 70.93, 452.3\n",
      "Plot: Val, 11, 2.881, 36.77, 452.3\n",
      "Plot: Train, 12, 0.786, 80.16, 493.2\n",
      "Plot: Val, 12, 2.760, 38.55, 493.2\n",
      "Plot: Train, 13, 0.599, 82.02, 534.2\n",
      "Plot: Val, 13, 3.054, 37.87, 534.2\n",
      "Plot: Train, 14, 0.504, 81.81, 575.0\n",
      "Plot: Val, 14, 3.441, 36.88, 575.0\n",
      "Plot: Train, 15, 0.392, 87.45, 615.9\n",
      "Plot: Val, 15, 3.399, 37.92, 615.9\n",
      "Plot: Train, 16, 0.133, 93.32, 656.8\n",
      "Plot: Val, 16, 3.618, 38.42, 656.8\n",
      "Plot: Train, 17, 0.446, 88.91, 697.6\n",
      "Plot: Val, 17, 3.730, 36.47, 697.6\n",
      "Plot: Train, 18, 0.242, 90.59, 738.3\n",
      "Plot: Val, 18, 3.989, 37.48, 738.3\n",
      "Plot: Train, 19, 0.239, 96.06, 778.0\n",
      "Plot: Val, 19, 3.775, 39.60, 778.0\n",
      "Plot: Train, 20, 0.077, 96.83, 815.3\n",
      "Plot: Val, 20, 3.750, 39.99, 815.3\n",
      "Plot: Train, 21, 0.075, 96.24, 852.3\n",
      "Plot: Val, 21, 3.743, 39.85, 852.3\n",
      "Plot: Train, 25, 0.015, 99.57, 1002.1\n",
      "Plot: Val, 25, 4.192, 41.66, 1002.1\n",
      "Plot: Test, 4.192, 41.66, 1002.1\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 1\n",
      "Replace layers list is: [0]\n",
      "Number of og layers are 0, number of new layers are 1\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [19]\n",
      "Number of og layers are 19, number of new layers are 1\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): approx_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): approx_Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=25, weight_decay=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 0, 6.941, 0.00, 0.0\n",
      "Plot: Val, 0, 6.940, 0.00, 0.0\n",
      "Plot: Train, 1, 4.339, 14.35, 36.6\n",
      "Plot: Val, 1, 3.967, 12.74, 36.6\n",
      "Plot: Train, 2, 3.238, 22.61, 73.0\n",
      "Plot: Val, 2, 3.377, 19.31, 73.0\n",
      "Plot: Train, 3, 3.534, 22.38, 109.4\n",
      "Plot: Val, 3, 3.533, 19.84, 109.4\n",
      "Plot: Train, 4, 2.443, 34.80, 145.8\n",
      "Plot: Val, 4, 2.993, 27.70, 145.8\n",
      "Plot: Train, 5, 2.610, 35.98, 182.0\n",
      "Plot: Val, 5, 3.085, 28.12, 182.0\n",
      "Plot: Train, 6, 1.748, 46.93, 218.2\n",
      "Plot: Val, 6, 2.702, 33.71, 218.2\n",
      "Plot: Train, 7, 2.348, 43.50, 254.4\n",
      "Plot: Val, 7, 3.228, 30.88, 254.4\n",
      "Plot: Train, 8, 1.441, 56.43, 291.0\n",
      "Plot: Val, 8, 2.623, 35.00, 291.0\n",
      "Plot: Train, 9, 1.196, 61.78, 327.9\n",
      "Plot: Val, 9, 2.746, 36.40, 327.9\n",
      "Plot: Train, 10, 1.223, 62.86, 365.2\n",
      "Plot: Val, 10, 2.960, 34.89, 365.2\n",
      "Plot: Train, 11, 1.360, 62.82, 402.9\n",
      "Plot: Val, 11, 3.204, 32.62, 402.9\n",
      "Plot: Train, 12, 0.807, 78.17, 441.6\n",
      "Plot: Val, 12, 2.843, 37.38, 441.6\n",
      "Plot: Train, 13, 0.502, 84.14, 481.4\n",
      "Plot: Val, 13, 2.995, 38.75, 481.4\n",
      "Plot: Train, 14, 0.534, 83.24, 521.5\n",
      "Plot: Val, 14, 3.313, 37.04, 521.5\n",
      "Plot: Train, 15, 0.325, 87.91, 562.2\n",
      "Plot: Val, 15, 3.531, 37.68, 562.2\n",
      "Plot: Train, 16, 0.158, 91.71, 602.5\n",
      "Plot: Val, 16, 3.679, 38.45, 602.5\n",
      "Plot: Train, 17, 0.192, 92.97, 639.7\n",
      "Plot: Val, 17, 3.534, 38.27, 639.7\n",
      "Plot: Train, 18, 0.288, 91.77, 676.3\n",
      "Plot: Val, 18, 4.062, 38.25, 676.3\n",
      "Plot: Train, 19, 0.245, 93.02, 712.6\n",
      "Plot: Val, 19, 4.026, 38.50, 712.6\n",
      "Plot: Train, 20, 0.085, 96.46, 748.9\n",
      "Plot: Val, 20, 3.991, 39.93, 748.9\n",
      "Plot: Train, 21, 0.091, 98.38, 785.0\n",
      "Plot: Val, 21, 3.845, 40.32, 785.0\n",
      "Plot: Train, 22, 0.150, 96.30, 821.1\n",
      "Plot: Val, 22, 3.853, 39.82, 821.1\n",
      "Plot: Train, 23, 0.195, 95.08, 857.2\n",
      "Plot: Val, 23, 4.282, 38.77, 857.2\n",
      "Plot: Train, 24, 0.089, 94.79, 893.6\n",
      "Plot: Val, 24, 4.418, 38.40, 893.6\n",
      "Plot: Train, 25, 0.117, 97.75, 930.3\n",
      "Plot: Val, 25, 4.038, 39.82, 930.3\n",
      "Plot: Test, 4.038, 39.82, 930.3\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 1\n",
      "Replace layers list is: [0]\n",
      "Number of og layers are 0, number of new layers are 1\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [19]\n",
      "Number of og layers are 19, number of new layers are 1\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): approx_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): approx_Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=25, weight_decay=0\n",
      "Plot: Train, 0, 6.941, 0.00, 0.0\n",
      "Plot: Val, 0, 6.940, 0.00, 0.0\n",
      "Plot: Train, 1, 4.158, 13.45, 35.5\n",
      "Plot: Val, 1, 3.907, 12.30, 35.5\n",
      "Plot: Train, 2, 3.293, 20.28, 71.6\n",
      "Plot: Val, 2, 3.515, 17.42, 71.6\n",
      "Plot: Train, 3, 3.218, 26.51, 108.7\n",
      "Plot: Val, 3, 3.245, 23.32, 108.7\n",
      "Plot: Train, 4, 2.663, 30.89, 146.5\n",
      "Plot: Val, 4, 3.112, 24.57, 146.5\n",
      "Plot: Train, 5, 2.368, 37.57, 184.5\n",
      "Plot: Val, 5, 2.939, 29.84, 184.5\n",
      "Plot: Train, 6, 1.710, 44.24, 223.2\n",
      "Plot: Val, 6, 2.764, 32.32, 223.2\n",
      "Plot: Train, 7, 1.919, 48.06, 261.9\n",
      "Plot: Val, 7, 2.832, 33.14, 261.9\n",
      "Plot: Train, 8, 1.865, 50.49, 299.9\n",
      "Plot: Val, 8, 2.819, 33.19, 299.9\n",
      "Plot: Train, 9, 1.321, 60.81, 338.0\n",
      "Plot: Val, 9, 2.637, 35.83, 338.0\n",
      "Plot: Train, 10, 1.316, 61.39, 376.7\n",
      "Plot: Val, 10, 2.812, 35.49, 376.7\n",
      "Plot: Train, 11, 1.277, 69.03, 415.7\n",
      "Plot: Val, 11, 2.947, 36.22, 415.7\n",
      "Plot: Train, 12, 1.189, 76.83, 454.4\n",
      "Plot: Val, 12, 2.798, 37.27, 454.4\n",
      "Plot: Train, 13, 0.461, 80.55, 493.0\n",
      "Plot: Val, 13, 3.082, 38.13, 493.0\n",
      "Plot: Train, 14, 0.504, 78.50, 531.5\n",
      "Plot: Val, 14, 3.689, 34.88, 531.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 15, 0.362, 87.33, 569.9\n",
      "Plot: Val, 15, 3.325, 38.11, 569.9\n",
      "Plot: Train, 16, 0.204, 93.70, 608.3\n",
      "Plot: Val, 16, 3.603, 38.76, 608.3\n",
      "Plot: Train, 17, 0.141, 91.76, 646.7\n",
      "Plot: Val, 17, 3.739, 37.34, 646.7\n",
      "Plot: Train, 18, 0.232, 93.55, 685.1\n",
      "Plot: Val, 18, 4.276, 38.74, 685.1\n",
      "Plot: Train, 19, 0.260, 92.75, 723.4\n",
      "Plot: Val, 19, 4.014, 38.51, 723.4\n",
      "Plot: Train, 20, 0.189, 94.26, 761.6\n",
      "Plot: Val, 20, 4.071, 39.16, 761.6\n",
      "Plot: Train, 21, 0.157, 96.11, 799.8\n",
      "Plot: Val, 21, 4.001, 39.13, 799.8\n",
      "Plot: Train, 22, 0.069, 94.69, 837.9\n",
      "Plot: Val, 22, 3.852, 39.14, 837.9\n",
      "Plot: Train, 23, 0.181, 95.81, 876.1\n",
      "Plot: Val, 23, 4.241, 38.97, 876.1\n",
      "Plot: Train, 24, 0.015, 98.28, 914.2\n",
      "Plot: Val, 24, 4.199, 40.29, 914.2\n",
      "Plot: Train, 25, 0.071, 98.16, 952.4\n",
      "Plot: Val, 25, 3.938, 40.25, 952.4\n",
      "Plot: Test, 3.938, 40.25, 952.4\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 1\n",
      "Replace layers list is: [0]\n",
      "Number of og layers are 0, number of new layers are 1\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [19]\n",
      "Number of og layers are 19, number of new layers are 1\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): approx_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): approx_Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=25, weight_decay=0\n",
      "Plot: Train, 0, 6.941, 0.00, 0.0\n",
      "Plot: Val, 0, 6.940, 0.00, 0.0\n",
      "Plot: Train, 1, 4.051, 14.85, 37.0\n",
      "Plot: Val, 1, 3.812, 14.08, 37.0\n",
      "Plot: Train, 2, 3.142, 20.90, 74.4\n",
      "Plot: Val, 2, 3.459, 17.85, 74.4\n",
      "Plot: Train, 3, 3.027, 25.21, 111.6\n",
      "Plot: Val, 3, 3.255, 21.56, 111.6\n",
      "Plot: Train, 4, 2.627, 28.35, 148.5\n",
      "Plot: Val, 4, 3.385, 23.16, 148.5\n",
      "Plot: Train, 5, 2.325, 39.08, 185.8\n",
      "Plot: Val, 5, 2.914, 30.92, 185.8\n",
      "Plot: Train, 6, 2.062, 42.77, 223.2\n",
      "Plot: Val, 6, 2.816, 31.37, 223.2\n",
      "Plot: Train, 7, 2.027, 46.48, 260.1\n",
      "Plot: Val, 7, 2.925, 31.99, 260.1\n",
      "Plot: Train, 8, 1.639, 52.95, 296.9\n",
      "Plot: Val, 8, 2.657, 34.28, 296.9\n",
      "Plot: Train, 9, 1.574, 58.29, 334.3\n",
      "Plot: Val, 9, 2.771, 35.29, 334.3\n",
      "Plot: Train, 10, 1.115, 66.21, 371.5\n",
      "Plot: Val, 10, 2.763, 36.63, 371.5\n",
      "Plot: Train, 11, 0.905, 72.34, 408.3\n",
      "Plot: Val, 11, 2.892, 36.97, 408.3\n",
      "Plot: Train, 12, 0.928, 73.47, 444.8\n",
      "Plot: Val, 12, 2.837, 36.27, 444.8\n",
      "Plot: Train, 13, 0.612, 79.45, 482.0\n",
      "Plot: Val, 13, 2.999, 38.08, 482.0\n",
      "Plot: Train, 14, 0.513, 83.33, 519.3\n",
      "Plot: Val, 14, 3.302, 37.12, 519.3\n",
      "Plot: Train, 15, 0.549, 85.42, 556.1\n",
      "Plot: Val, 15, 3.525, 37.06, 556.1\n",
      "Plot: Train, 16, 0.162, 89.93, 592.9\n",
      "Plot: Val, 16, 3.479, 38.44, 592.9\n",
      "Plot: Train, 17, 0.273, 91.74, 630.2\n",
      "Plot: Val, 17, 3.583, 38.29, 630.2\n",
      "Plot: Train, 18, 0.154, 92.09, 667.4\n",
      "Plot: Val, 18, 4.085, 37.88, 667.4\n",
      "Plot: Train, 19, 0.113, 96.21, 704.2\n",
      "Plot: Val, 19, 3.780, 40.44, 704.2\n",
      "Plot: Train, 20, 0.094, 97.15, 740.9\n",
      "Plot: Val, 20, 3.788, 40.20, 740.9\n",
      "Plot: Train, 21, 0.073, 97.20, 777.7\n",
      "Plot: Val, 21, 3.874, 39.47, 777.7\n",
      "Plot: Train, 22, 0.181, 96.05, 815.1\n",
      "Plot: Val, 22, 3.678, 39.77, 815.1\n",
      "Plot: Train, 23, 0.085, 97.74, 851.7\n",
      "Plot: Val, 23, 3.854, 40.49, 851.7\n",
      "Plot: Train, 24, 0.096, 96.77, 888.5\n",
      "Plot: Val, 24, 4.314, 39.84, 888.5\n",
      "Plot: Train, 25, 0.166, 97.30, 925.8\n",
      "Plot: Val, 25, 4.169, 39.56, 925.8\n",
      "Plot: Test, 4.169, 39.56, 925.8\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 1\n",
      "Replace layers list is: [0]\n",
      "Number of og layers are 0, number of new layers are 1\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [19]\n",
      "Number of og layers are 19, number of new layers are 1\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): approx_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): approx_Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=25, weight_decay=0\n",
      "Plot: Train, 0, 6.941, 0.00, 0.0\n",
      "Plot: Val, 0, 6.940, 0.00, 0.0\n",
      "Plot: Train, 1, 4.907, 10.12, 35.7\n",
      "Plot: Val, 1, 4.429, 9.15, 35.7\n",
      "Plot: Train, 2, 2.990, 21.67, 72.0\n",
      "Plot: Val, 2, 3.342, 18.85, 72.0\n",
      "Plot: Train, 3, 3.077, 26.94, 108.1\n",
      "Plot: Val, 3, 3.093, 23.31, 108.1\n",
      "Plot: Train, 4, 2.287, 35.30, 143.6\n",
      "Plot: Val, 4, 2.939, 27.99, 143.6\n",
      "Plot: Train, 5, 2.446, 40.46, 179.4\n",
      "Plot: Val, 5, 2.747, 31.49, 179.4\n",
      "Plot: Train, 6, 1.951, 42.37, 215.8\n",
      "Plot: Val, 6, 2.880, 30.58, 215.8\n",
      "Plot: Train, 7, 1.920, 41.85, 251.9\n",
      "Plot: Val, 7, 3.137, 29.49, 251.9\n",
      "Plot: Train, 8, 1.618, 52.94, 288.0\n",
      "Plot: Val, 8, 2.746, 33.24, 288.0\n",
      "Plot: Train, 9, 1.381, 59.23, 324.1\n",
      "Plot: Val, 9, 2.767, 34.77, 324.1\n",
      "Plot: Train, 10, 1.144, 67.81, 360.1\n",
      "Plot: Val, 10, 2.715, 37.30, 360.1\n",
      "Plot: Train, 11, 0.974, 67.72, 396.1\n",
      "Plot: Val, 11, 2.886, 34.51, 396.1\n",
      "Plot: Train, 12, 0.683, 75.91, 432.1\n",
      "Plot: Val, 12, 2.910, 36.33, 432.1\n",
      "Plot: Train, 13, 0.710, 79.67, 468.0\n",
      "Plot: Val, 13, 3.098, 36.71, 468.0\n",
      "Plot: Train, 14, 0.527, 85.51, 503.9\n",
      "Plot: Val, 14, 3.329, 37.11, 503.9\n",
      "Plot: Train, 15, 0.396, 83.45, 539.8\n",
      "Plot: Val, 15, 3.574, 35.50, 539.8\n",
      "Plot: Train, 16, 0.255, 85.63, 575.6\n",
      "Plot: Val, 16, 3.503, 35.89, 575.6\n",
      "Plot: Train, 17, 0.440, 89.13, 611.5\n",
      "Plot: Val, 17, 3.583, 36.64, 611.5\n",
      "Plot: Train, 18, 0.121, 95.62, 647.3\n",
      "Plot: Val, 18, 3.987, 38.90, 647.3\n",
      "Plot: Train, 19, 0.135, 97.36, 683.0\n",
      "Plot: Val, 19, 3.931, 39.56, 683.0\n",
      "Plot: Train, 20, 0.053, 97.75, 718.8\n",
      "Plot: Val, 20, 3.828, 39.24, 718.8\n",
      "Plot: Train, 21, 0.040, 98.29, 754.5\n",
      "Plot: Val, 21, 3.725, 39.53, 754.5\n",
      "Plot: Train, 22, 0.173, 93.18, 790.2\n",
      "Plot: Val, 22, 4.180, 37.10, 790.2\n",
      "Plot: Train, 23, 0.214, 93.92, 826.1\n",
      "Plot: Val, 23, 3.961, 37.70, 826.1\n",
      "Plot: Train, 24, 0.059, 95.53, 861.8\n",
      "Plot: Val, 24, 4.000, 38.15, 861.8\n",
      "Plot: Train, 25, 0.041, 98.38, 897.4\n",
      "Plot: Val, 25, 4.098, 39.53, 897.4\n",
      "Plot: Test, 4.098, 39.53, 897.4\n"
     ]
    }
   ],
   "source": [
    "gradinit_params = {\n",
    "    \"gradinit_iters\": 200,\n",
    "    \"gradinit_alg\": \"adam\", #sgd\n",
    "    \"gradinit_lr\": 1e-4, \n",
    "    \"gradinit_grad_clip\": 1,\n",
    "}\n",
    "model_params = {\n",
    "#     \"gradinit\": gradinit_params,\n",
    "#     \"convnorm\" : {\"mode_conv\": [('first_frac', 0.25)], \"mode_bn\": [('first_frac', 0.25)]},\n",
    "    \"approx_mult\" : {'mult_val' : 0.8, 'mode_linear' : [('last_num', 1)], 'mode_conv' : [('last_num', 1)]},\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-3,\n",
    "    \"num_epochs\" : 25,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 1024,\n",
    "}\n",
    "\n",
    "def test_setup():\n",
    "    for mult_val in [0.2, 0.4, 0.6, 0.8, 1.0][::-1]:\n",
    "        model_params['approx_mult']['mult_val'] = mult_val\n",
    "        train_model('Resnet18', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=25, weight_decay=0\n",
      "Plot: Train, 0, 6.908, 0.00, 0.0\n",
      "Plot: Val, 0, 6.911, 0.00, 0.0\n",
      "Plot: Train, 1, 3.316, 18.32, 35.9\n",
      "Plot: Val, 1, 3.257, 16.56, 35.9\n",
      "Plot: Train, 2, 3.330, 22.81, 72.5\n",
      "Plot: Val, 2, 3.212, 19.94, 72.5\n",
      "Plot: Train, 3, 2.775, 30.77, 110.0\n",
      "Plot: Val, 3, 2.976, 26.13, 110.0\n",
      "Plot: Train, 4, 2.269, 41.24, 147.9\n",
      "Plot: Val, 4, 2.442, 32.33, 147.9\n",
      "Plot: Train, 5, 2.003, 43.30, 185.8\n",
      "Plot: Val, 5, 2.575, 32.50, 185.8\n",
      "Plot: Train, 6, 1.867, 50.02, 224.2\n",
      "Plot: Val, 6, 2.646, 35.30, 224.2\n",
      "Plot: Train, 7, 1.407, 59.14, 262.6\n",
      "Plot: Val, 7, 2.571, 37.53, 262.6\n",
      "Plot: Train, 8, 0.834, 64.35, 301.0\n",
      "Plot: Val, 8, 2.497, 37.50, 301.0\n",
      "Plot: Train, 9, 0.913, 69.41, 339.4\n",
      "Plot: Val, 9, 2.584, 38.30, 339.4\n",
      "Plot: Train, 10, 0.800, 77.96, 377.4\n",
      "Plot: Val, 10, 3.029, 38.78, 377.4\n",
      "Plot: Train, 11, 0.697, 81.11, 415.3\n",
      "Plot: Val, 11, 3.124, 38.13, 415.3\n",
      "Plot: Train, 15, 0.103, 94.80, 567.5\n",
      "Plot: Val, 15, 3.542, 40.26, 567.5\n",
      "Plot: Train, 16, 0.057, 95.98, 605.8\n",
      "Plot: Val, 16, 3.857, 40.54, 605.8\n",
      "Plot: Train, 17, 0.054, 96.73, 643.9\n",
      "Plot: Val, 17, 4.453, 40.78, 643.9\n",
      "Plot: Train, 18, 0.044, 97.69, 682.4\n",
      "Plot: Val, 18, 4.028, 40.86, 682.4\n",
      "Plot: Train, 19, 0.091, 97.57, 720.4\n",
      "Plot: Val, 19, 4.050, 41.35, 720.4\n",
      "Plot: Train, 20, 0.136, 96.73, 758.8\n",
      "Plot: Val, 20, 4.379, 40.15, 758.8\n",
      "Plot: Train, 21, 0.112, 97.23, 796.7\n",
      "Plot: Val, 21, 4.124, 40.17, 796.7\n",
      "Plot: Train, 22, 0.144, 95.93, 834.6\n",
      "Plot: Val, 22, 4.569, 40.12, 834.6\n",
      "Plot: Train, 23, 0.034, 96.59, 872.8\n",
      "Plot: Val, 23, 4.030, 40.21, 872.8\n",
      "Plot: Train, 24, 0.039, 98.43, 910.7\n",
      "Plot: Val, 24, 4.112, 40.74, 910.7\n",
      "Plot: Train, 25, 0.082, 97.35, 948.2\n",
      "Plot: Val, 25, 4.422, 40.26, 948.2\n",
      "Plot: Test, 4.422, 40.26, 948.2\n"
     ]
    }
   ],
   "source": [
    "gradinit_params = {\n",
    "    \"gradinit_iters\": 200,\n",
    "    \"gradinit_alg\": \"adam\", #sgd\n",
    "    \"gradinit_lr\": 1e-4, \n",
    "    \"gradinit_grad_clip\": 1,\n",
    "}\n",
    "model_params = {\n",
    "#     \"gradinit\": gradinit_params,\n",
    "#     \"convnorm\" : {\"mode_conv\": [('first_frac', 0.25)], \"mode_bn\": [('first_frac', 0.25)]},\n",
    "#     \"approx_mult\" : {'mult_val' : 0.8, 'mode_linear' : [('last_num', 1)], 'mode_conv' : [('last_num', 1)]},\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-3,\n",
    "    \"num_epochs\" : 25,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 512,\n",
    "}\n",
    "\n",
    "def test_setup():\n",
    "    train_model('Resnet18', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_p37",
   "language": "python",
   "name": "pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
