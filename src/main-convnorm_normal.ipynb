{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1653204886178,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "bFB6WDmimTpS",
    "outputId": "672d2a42-ea4c-43f3-e1ca-1367c2868357"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# FOLDERNAME = 'CS231n_project/'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4353,
     "status": "ok",
     "timestamp": 1653204890527,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "ejjKJYC2YffB",
    "outputId": "7a1aad97-7fc6-4c21-fa04-24f4508284e0"
   },
   "outputs": [],
   "source": [
    "# !pip install torch==1.7 torchvision==0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6003,
     "status": "ok",
     "timestamp": 1653204896527,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "TzJV-LLVhBt5",
    "outputId": "03468936-f099-4c8f-935b-9dfc257e456a"
   },
   "outputs": [],
   "source": [
    "# %cd approx/src/pytorch/cpp\n",
    "# !python setup.py install\n",
    "# %cd ../../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1653204897473,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "uGvmWqNZD2hh",
    "outputId": "fd0ce3ef-78c9-4a72-bef1-a3b94a03a0e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from conv_norm import PreConv\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from utils import ImportanceSampler\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653204897475,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "BMatykiuGnJT"
   },
   "outputs": [],
   "source": [
    "from utils import get_accuracy, load_dataset\n",
    "from models import get_model\n",
    "check_accuracy = lambda loader, model: get_accuracy(loader, model, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1653206021690,
     "user": {
      "displayName": "Shubham Jain",
      "userId": "09959993659061500830"
     },
     "user_tz": 420
    },
    "id": "dLHtcW9UHqOt"
   },
   "outputs": [],
   "source": [
    "def train_model(model_name, dataset_name, model_params={}, hyperparams={}):\n",
    "\n",
    "  learning_rate = hyperparams.get('lr', 1e-3)\n",
    "  num_epochs = hyperparams.get('num_epochs', 10)\n",
    "  weight_decay = hyperparams.get('weight_decay', 0)\n",
    "  train_ratio = hyperparams.get('train_ratio', 0.8)\n",
    "  batch_size = hyperparams.get('batch_size', 64)\n",
    "  seed = hyperparams.get('seed', 0)\n",
    "  imp_sampling = model_params.get('importance_sampling', False)\n",
    "  gamma = model_params.get('gamma', 0.9)\n",
    "\n",
    "  torch.manual_seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  loader_train, loader_val, loader_test, num_train, num_channels = load_dataset(dataset_name, train_ratio, batch_size)\n",
    "  model = get_model(model_name, model_params, learning_rate, loader_train, num_channels, device)\n",
    "\n",
    "  print(\"Model architecture:\")\n",
    "  print(model)\n",
    "\n",
    "  print(f'INFO: Training {model_name} on {dataset_name} with lr {learning_rate}, num_epochs={num_epochs}, weight_decay={weight_decay}')\n",
    "\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "\n",
    "  epoch_vals = []\n",
    "  \n",
    "  weight = torch.tensor([1.0]*num_train)\n",
    "\n",
    "  t_acc, t_loss = check_accuracy(loader_train, model)\n",
    "  val_acc, val_loss = check_accuracy(loader_val, model)\n",
    "  \n",
    "  start = timer()\n",
    "  c_time = timer()-start\n",
    "\n",
    "  print(f'Plot: Train, {0}, {t_loss:.3f}, {t_acc:.2f}, {c_time:.1f}')\n",
    "  print(f'Plot: Val, {0}, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  for e in range(num_epochs):\n",
    "    model.train()\n",
    "    doUniform = (e == 0) or (imp_sampling == False)\n",
    "    loader_train_sampled = loader_train\n",
    "    if not doUniform:\n",
    "      train_sampler = ImportanceSampler(num_train, weight, batch_size)\n",
    "      loader_train_sampled, _, _, _, _ = load_dataset(dataset_name, train_ratio, batch_size, train_sampler)\n",
    "    \n",
    "    for t, tpl in enumerate(loader_train_sampled):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()  # put model to training mode\n",
    "        x = tpl[0].to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "        y = tpl[1].to(device=device, dtype=torch.long)\n",
    "\n",
    "        scores = model(x)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not doUniform:\n",
    "          idx = tpl[2]\n",
    "          weight[idx] = gamma * weight[idx] + (1 - gamma) * float(loss)\n",
    "\n",
    "    t_acc, t_loss = check_accuracy(loader_train, model)\n",
    "    model.eval()\n",
    "    val_acc, val_loss = check_accuracy(loader_val, model)\n",
    "    c_time = timer()-start\n",
    "\n",
    "    print(f'Plot: Train, {e+1}, {t_loss:.3f}, {t_acc:.2f}, {c_time:.1f}')\n",
    "    print(f'Plot: Val, {e+1}, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  test_acc, test_loss = check_accuracy(loader_test, model)\n",
    "  print(f'Plot: Test, {val_loss:.3f}, {val_acc:.2f}, {c_time:.1f}')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhJmW7E1cMBF",
    "outputId": "d812c321-f54b-4aaf-c69b-ce76893369c6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b15667519ab419ca8f6be112691a76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Number of og layers are 20, number of new layers are 20\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Number of og layers are 0, number of new layers are 20\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): PreConv(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
      "    (bpconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): PreConv(\n",
      "          64, 128, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (bpconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), groups=128)\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): PreConv(\n",
      "          128, 256, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (bpconv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256)\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (bpconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): PreConv(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (bpconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), groups=512)\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=15, weight_decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/CS231n-Faster-Classifier/src/conv_norm.py:112: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  f_input = torch.rfft(cout, 2, normalized=False, onesided=True)\n",
      "/home/ubuntu/CS231n-Faster-Classifier/src/conv_norm.py:123: UserWarning: The function torch.irfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.ifft or torch.fft.irfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/aten/src/ATen/native/SpectralOps.cpp:602.)\n",
      "  output = torch.irfft(compl_mul_2D(f_input, V), 2, normalized=False, signal_sizes=(final_size_x,final_size_y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 0, 6.898, 0.00, 0.0\n",
      "Plot: Val, 0, 6.918, 0.00, 0.0\n",
      "Plot: Train, 1, 4.589, 1.04, 74.1\n",
      "Plot: Val, 1, 4.610, 1.05, 74.1\n",
      "Plot: Train, 2, 4.468, 3.62, 179.3\n",
      "Plot: Val, 2, 4.342, 3.47, 179.3\n",
      "Plot: Train, 3, 4.017, 5.42, 284.5\n",
      "Plot: Val, 3, 4.180, 5.33, 284.5\n",
      "Plot: Train, 4, 3.875, 8.42, 391.2\n",
      "Plot: Val, 4, 3.965, 7.86, 391.2\n",
      "Plot: Train, 5, 3.428, 12.73, 497.5\n",
      "Plot: Val, 5, 3.706, 12.03, 497.5\n",
      "Plot: Train, 6, 3.361, 14.15, 603.4\n",
      "Plot: Val, 6, 3.693, 12.81, 603.4\n",
      "Plot: Train, 7, 3.614, 17.41, 710.5\n",
      "Plot: Val, 7, 3.533, 15.68, 710.5\n",
      "Plot: Train, 8, 3.004, 21.00, 817.0\n",
      "Plot: Val, 8, 3.287, 18.45, 817.0\n",
      "Plot: Train, 9, 3.054, 21.97, 922.9\n",
      "Plot: Val, 9, 3.354, 18.89, 922.9\n",
      "Plot: Train, 10, 2.967, 24.27, 1022.4\n",
      "Plot: Val, 10, 3.199, 20.76, 1022.4\n",
      "Plot: Train, 11, 2.679, 25.91, 1122.8\n",
      "Plot: Val, 11, 3.171, 22.04, 1122.8\n",
      "Plot: Train, 12, 2.732, 29.97, 1225.6\n",
      "Plot: Val, 12, 3.019, 24.72, 1225.6\n",
      "Plot: Train, 13, 2.606, 31.81, 1326.6\n",
      "Plot: Val, 13, 2.986, 25.74, 1326.6\n",
      "Plot: Train, 14, 2.483, 32.55, 1421.4\n",
      "Plot: Val, 14, 3.155, 24.12, 1421.4\n",
      "Plot: Train, 15, 2.409, 38.22, 1517.6\n",
      "Plot: Val, 15, 2.911, 28.26, 1517.6\n",
      "Plot: Test, 2.911, 28.26, 1517.6\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Number of og layers are 20, number of new layers are 15\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Number of og layers are 5, number of new layers are 15\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): PreConv(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
      "    (bpconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): PreConv(\n",
      "          64, 128, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (bpconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), groups=128)\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): PreConv(\n",
      "          128, 256, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (bpconv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256)\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=15, weight_decay=0\n",
      "Plot: Train, 0, 6.884, 0.00, 0.0\n",
      "Plot: Val, 0, 6.894, 0.00, 0.0\n",
      "Plot: Train, 1, 8.608, 1.39, 121.1\n",
      "Plot: Val, 1, 8.333, 1.30, 121.1\n",
      "Plot: Train, 3, 6.853, 7.38, 377.6\n",
      "Plot: Val, 3, 6.445, 6.55, 377.6\n",
      "Plot: Train, 4, 3.436, 14.42, 506.4\n",
      "Plot: Val, 4, 4.053, 12.71, 506.4\n",
      "Plot: Train, 5, 5.563, 13.27, 622.2\n",
      "Plot: Val, 5, 5.765, 11.35, 622.2\n",
      "Plot: Train, 6, 3.693, 19.33, 753.0\n",
      "Plot: Val, 6, 4.384, 15.84, 753.0\n",
      "Plot: Train, 7, 3.908, 23.09, 883.5\n",
      "Plot: Val, 7, 4.599, 18.67, 883.5\n",
      "Plot: Train, 8, 3.051, 27.02, 1014.0\n",
      "Plot: Val, 8, 4.159, 20.48, 1014.0\n",
      "Plot: Train, 9, 3.782, 24.55, 1144.4\n",
      "Plot: Val, 9, 4.677, 18.18, 1144.4\n",
      "Plot: Train, 10, 4.733, 17.72, 1275.1\n",
      "Plot: Val, 10, 5.814, 13.91, 1275.1\n",
      "Plot: Train, 11, 2.984, 29.29, 1406.7\n",
      "Plot: Val, 11, 4.512, 19.61, 1406.7\n",
      "Plot: Train, 12, 2.835, 29.03, 1538.0\n",
      "Plot: Val, 12, 4.818, 19.27, 1538.0\n",
      "Plot: Train, 13, 2.503, 37.49, 1668.7\n",
      "Plot: Val, 13, 4.559, 23.58, 1668.7\n",
      "Plot: Train, 14, 3.722, 31.45, 1752.2\n",
      "Plot: Val, 14, 5.510, 18.98, 1752.2\n",
      "Plot: Train, 15, 1.820, 45.30, 1817.0\n",
      "Plot: Val, 15, 4.138, 25.68, 1817.0\n",
      "Plot: Test, 4.138, 25.68, 1817.0\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Number of og layers are 20, number of new layers are 10\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Number of og layers are 10, number of new layers are 10\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): PreConv(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
      "    (bpconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): PreConv(\n",
      "          64, 128, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (bpconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), groups=128)\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=15, weight_decay=0\n",
      "Plot: Train, 0, 6.871, 0.00, 0.0\n",
      "Plot: Val, 0, 6.904, 0.00, 0.0\n",
      "Plot: Train, 1, 4.622, 10.14, 61.3\n",
      "Plot: Val, 1, 4.342, 9.42, 61.3\n",
      "Plot: Train, 2, 4.747, 11.37, 121.7\n",
      "Plot: Val, 2, 4.374, 10.99, 121.7\n",
      "Plot: Train, 3, 3.711, 21.43, 179.4\n",
      "Plot: Val, 3, 3.602, 18.63, 179.4\n",
      "Plot: Train, 4, 3.045, 24.31, 235.8\n",
      "Plot: Val, 4, 3.748, 20.93, 235.8\n",
      "Plot: Train, 5, 2.400, 34.14, 292.2\n",
      "Plot: Val, 5, 3.118, 26.51, 292.2\n",
      "Plot: Train, 6, 2.503, 34.88, 349.1\n",
      "Plot: Val, 6, 3.395, 26.07, 349.1\n",
      "Plot: Train, 7, 1.759, 44.12, 406.8\n",
      "Plot: Val, 7, 3.039, 30.81, 406.8\n",
      "Plot: Train, 8, 1.460, 54.86, 466.5\n",
      "Plot: Val, 8, 2.525, 35.30, 466.5\n",
      "Plot: Train, 9, 1.736, 47.58, 527.6\n",
      "Plot: Val, 9, 3.052, 30.28, 527.6\n",
      "Plot: Train, 10, 1.746, 58.57, 588.7\n",
      "Plot: Val, 10, 2.945, 33.28, 588.7\n",
      "Plot: Train, 11, 0.708, 63.05, 649.5\n",
      "Plot: Val, 11, 2.899, 35.00, 649.5\n",
      "Plot: Train, 12, 1.085, 68.90, 710.3\n",
      "Plot: Val, 12, 3.069, 35.48, 710.3\n",
      "Plot: Train, 13, 0.827, 64.77, 771.0\n",
      "Plot: Val, 13, 3.412, 32.20, 771.0\n",
      "Plot: Train, 14, 0.681, 77.70, 831.8\n",
      "Plot: Val, 14, 3.502, 35.86, 831.8\n",
      "Plot: Train, 15, 0.905, 81.43, 892.4\n",
      "Plot: Val, 15, 3.521, 35.67, 892.4\n",
      "Plot: Test, 3.521, 35.67, 892.4\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4]\n",
      "Number of og layers are 20, number of new layers are 5\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0, 1, 2, 3, 4]\n",
      "Number of og layers are 15, number of new layers are 5\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): PreConv(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
      "    (bpconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): PreConv(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (bpconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=15, weight_decay=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: Train, 0, 6.895, 0.00, 0.0\n",
      "Plot: Val, 0, 6.904, 0.00, 0.0\n",
      "Plot: Train, 1, 3.883, 16.52, 59.8\n",
      "Plot: Val, 1, 3.649, 15.19, 59.8\n",
      "Plot: Train, 2, 2.905, 26.05, 119.0\n",
      "Plot: Val, 2, 3.087, 22.91, 119.0\n",
      "Plot: Train, 3, 2.751, 32.28, 178.2\n",
      "Plot: Val, 3, 3.107, 26.13, 178.2\n",
      "Plot: Train, 4, 2.340, 36.18, 237.2\n",
      "Plot: Val, 4, 2.859, 28.93, 237.2\n",
      "Plot: Train, 5, 2.365, 39.09, 297.1\n",
      "Plot: Val, 5, 2.825, 29.82, 297.1\n",
      "Plot: Train, 6, 1.653, 45.77, 356.2\n",
      "Plot: Val, 6, 2.768, 32.71, 356.2\n",
      "Plot: Train, 7, 1.837, 55.81, 415.7\n",
      "Plot: Val, 7, 2.715, 36.28, 415.7\n",
      "Plot: Train, 8, 1.508, 55.18, 474.6\n",
      "Plot: Val, 8, 2.848, 34.26, 474.6\n",
      "Plot: Train, 9, 1.253, 61.87, 534.3\n",
      "Plot: Val, 9, 2.953, 35.30, 534.3\n",
      "Plot: Train, 10, 0.867, 70.69, 603.9\n",
      "Plot: Val, 10, 3.082, 36.13, 603.9\n",
      "Plot: Train, 11, 0.813, 75.88, 715.2\n",
      "Plot: Val, 11, 2.851, 35.87, 715.2\n",
      "Plot: Train, 12, 0.813, 80.92, 826.3\n",
      "Plot: Val, 12, 3.105, 36.95, 826.3\n",
      "Plot: Train, 13, 0.579, 79.03, 936.5\n",
      "Plot: Val, 13, 3.327, 35.61, 936.5\n",
      "Plot: Train, 15, 0.135, 92.09, 1172.3\n",
      "Plot: Val, 15, 3.463, 37.66, 1172.3\n",
      "Plot: Test, 3.463, 37.66, 1172.3\n",
      "Files already downloaded and verified\n",
      "CIFAR100 Train dataset raw mean: 0.4783550798892975, raw std dev: 0.2678655982017517\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO: Size of dataset: Training 40000, Validation 10000, Test 10000\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0]\n",
      "Number of og layers are 20, number of new layers are 1\n",
      "bn_pres is True\n",
      "Originally num layers were 20\n",
      "Replace layers list is: [0]\n",
      "Number of og layers are 19, number of new layers are 1\n",
      "Model architecture:\n",
      "ResNet(\n",
      "  (conv1): PreConv(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
      "    (bpconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "INFO: Training Resnet18 on CIFAR100 with lr 0.003, num_epochs=15, weight_decay=0\n",
      "Plot: Train, 0, 6.908, 0.00, 0.0\n",
      "Plot: Val, 0, 6.907, 0.00, 0.0\n",
      "Plot: Train, 1, 3.813, 11.25, 115.2\n",
      "Plot: Val, 1, 4.013, 10.43, 115.2\n",
      "Plot: Train, 2, 3.178, 19.27, 229.0\n",
      "Plot: Val, 2, 3.694, 17.43, 229.0\n",
      "Plot: Train, 3, 2.503, 29.07, 342.8\n",
      "Plot: Val, 3, 3.069, 25.02, 342.8\n",
      "Plot: Train, 4, 2.355, 35.98, 453.5\n",
      "Plot: Val, 4, 2.824, 29.92, 453.5\n",
      "Plot: Train, 5, 2.389, 38.31, 557.9\n",
      "Plot: Val, 5, 2.865, 31.08, 557.9\n",
      "Plot: Train, 6, 2.352, 34.68, 649.6\n",
      "Plot: Val, 6, 3.071, 26.57, 649.6\n",
      "Plot: Train, 7, 2.078, 45.01, 756.8\n",
      "Plot: Val, 7, 2.775, 32.31, 756.8\n",
      "Plot: Train, 8, 1.604, 45.91, 863.7\n",
      "Plot: Val, 8, 2.981, 31.60, 863.7\n",
      "Plot: Train, 9, 1.697, 55.31, 964.1\n",
      "Plot: Val, 9, 2.665, 35.61, 964.1\n",
      "Plot: Train, 10, 2.153, 53.17, 1064.7\n",
      "Plot: Val, 10, 3.005, 33.27, 1064.7\n",
      "Plot: Train, 11, 1.533, 63.16, 1170.3\n",
      "Plot: Val, 11, 3.049, 35.09, 1170.3\n",
      "Plot: Train, 12, 1.249, 70.44, 1280.4\n",
      "Plot: Val, 12, 2.990, 35.74, 1280.4\n",
      "Plot: Train, 13, 1.446, 62.66, 1388.9\n",
      "Plot: Val, 13, 3.603, 32.99, 1388.9\n",
      "Plot: Train, 14, 0.777, 79.27, 1467.5\n",
      "Plot: Val, 14, 3.406, 36.21, 1467.5\n",
      "Plot: Train, 15, 0.481, 80.81, 1518.3\n",
      "Plot: Val, 15, 3.398, 35.35, 1518.3\n",
      "Plot: Test, 3.398, 35.35, 1518.3\n"
     ]
    }
   ],
   "source": [
    "# gradinit_params = {\n",
    "#     \"gradinit_iters\": 50,\n",
    "#     \"gradinit_alg\": \"adam\", #sgd\n",
    "#     \"gradinit_lr\": 1e-2,\n",
    "#     \"gradinit_grad_clip\": 100,\n",
    "# }\n",
    "model_params = {\n",
    "#     \"gradinit\": gradinit_params,\n",
    "    \"convnorm\" : {\"mode_conv\": [('first_frac', 0.25)], \"mode_bn\": [('first_frac', 0.25)]},\n",
    "    # \"approx_mult\" : 0.2,\n",
    "    # \"importance_sampling\" : True,\n",
    "    # \"gamma\" : 0.9\n",
    "}\n",
    "hyperparams = {\n",
    "    \"lr\" : 3e-3,\n",
    "    \"num_epochs\" : 15,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"train_ratio\" : 0.8,\n",
    "    \"batch_size\" : 1024,\n",
    "}\n",
    "\n",
    "def test_setup():\n",
    "    modeList = [[('first_num', 1)], [('first_frac', 0.25)], [('first_frac', 0.5)], [('first_frac', 0.75)], [('first_frac', 1.0)]][::-1]\n",
    "    for mode in modeList:\n",
    "        model_params['convnorm'][\"mode_conv\"] = mode\n",
    "        model_params['convnorm'][\"mode_bn\"] = mode\n",
    "        train_model('Resnet18', 'CIFAR100', model_params, hyperparams)\n",
    "\n",
    "test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_p37",
   "language": "python",
   "name": "pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
